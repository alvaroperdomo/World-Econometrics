# CointegraciÃ³n

En los modelos univariados una tendencia estocÃ¡stica puede eliminarse por diferenciaciÃ³n, las series estacionarias resultantes se pueden estimar utilizando las tÃ©cnicas univariadas de Box-Jenkins. Anteriormente, la prÃ¡ctica convencional era generalizar esta idea a los modelos multivariados y diferenciar todas las variables no estacionarias utilizadas en un anÃ¡lisis de regresiÃ³n para luego estimar un modelo VAR en diferencias. Sin embargo, hoy en dÃ­a la forma adecuada de tratar las variables no estacionarias no es tan sencilla en un contexto multivariado. Es bastante posible que haya una combinaciÃ³n lineal de variables integradas que sea estacionaria y que por lo tanto configure una relaciÃ³n de largo plazo[^1]; si esto ocurre se dice que tales variables estÃ¡n **cointegradas**. 

[^1]: **En cierto sentido, el uso del tÃ©rmino equilibrio es desafortunado porque los teÃ³ricos econÃ³micos y los econometristas usan el tÃ©rmino de diferentes maneras. En teorÃ­a econÃ³mica usualmente se usa el tÃ©rmino para referirse a una igualdad entre transacciones deseadas y reales. El uso economÃ©trico del tÃ©rmino hace referencia a cualquier relaciÃ³n a largo plazo entre variables no estacionarias. La cointegraciÃ³n no requiere que la relaciÃ³n a largo plazo sea generada por las fuerzas del mercado o por las reglas de comportamiento de los individuos. SegÃºn Engle y Granger (1987) la relaciÃ³n de equilibrio puede ser causal, conductual o sim-plemente una relaciÃ³n de forma reducida entre variables con tendencias similares.** 

Para entender mejor lo que es cointegraciÃ³n considere el siguiente ejemplo: Asuma que hay $n$ variables $x_{1t}, x_{2t}, \dots, x_{nt}$ integradas del mismo orden que conforman un equilibrio de largo plazo representado por $\eqalign{\sum_{i=1}^n \beta_i x_{it}=0}$. Es decir, $\mathbf{B x_t}=0$ donde $\mathbf{B} = {\left\lbrack \matrix{\beta_1 & \beta_2 & ... & \beta_n} \right\rbrack}$ y 

$$ 
\mathbf{x_t} = \left[\begin{array}{ccc} 
x_{1t} \\ 
x_{2t} \\ 
\dots \\ 
x_{nt}  
\end{array}\right] 
$$ 

La desviaciÃ³n del equilibrio a largo plazo, llamado error de equilibrio es $e_t$, por lo tanto $e_t=\mathbf{\beta x_t}$. **Si el equilibrio es significativo, $e_t$ debe ser estacionario**. 

Engle y Granger (1987) proporcionan la siguiente definiciÃ³n de cointegraciÃ³n: Se dice que los componentes del vector 

$$ 
\mathbf{x_t} = \left[\begin{array}{ccc} 
x_{1t} \\ 
x_{2t} \\ 
\dots \\ 
x_{nt}  
\end{array}\right] 
$$ 

son cointegrados de orden $d,b$, denotado por $\mathbf{x_t}\sim CI(d,b)$  si 
1) Todos los componentes de $\mathbf{x_t}$ son integrados de orden $d$.
2) Existe un vector $\mathbf{B} = {\left\lbrack \matrix{\beta_1 & \beta_2 & ... & \beta_n} \right\rbrack}$ tal que la combinaciÃ³n lineal $\mathbf{\beta x_t}=0$  estÃ¡ integrada de orden $(d-b)$ donde $b>0$.

  El vector $B$ se llama el vector cointegrante.

Hay cuatro puntos importantes a tener en cuenta sobre la definiciÃ³n:
1) **La cointegraciÃ³n se refiere a una combinaciÃ³n lineal de variables no estacionarias**.

   El vector de cointegraciÃ³n no es Ãºnico. Si ${\left\lbrack \matrix{\beta_1 & \beta_2 & ... & \beta_n} \right\rbrack}$ es un vector de cointegraciÃ³n, entonces para cualquier $\lambda \not= 0$, ${\left\lbrack \matrix{\lambda\beta_1 & \lambda\beta_2 & \dots & \lambda\beta_n} \right\rbrack}$ tambiÃ©n es un vector de cointegraciÃ³n.

   Normalmente, una de las variables se usa para normalizar el vector de cointegraciÃ³n fijando su coeficiente en $1$. Por ejemplo, para normalizar el vector de cointegraciÃ³n con respecto a $x_{1t}$, simplemente se selecciona un $\lambda=\frac{1}{\beta_1}$.

2) **La cointegraciÃ³n se refiere a variables que estÃ¡n integradas en el mismo orden**.

   Esto no implica que todas las variables integradas estÃ©n cointegradas; por lo general, un conjunto de variables $I(d)$ no estÃ¡ cointegrado.[^3] 

   **Si dos variables son integradas de Ã³rdenes diferentes, no pueden estar cointegradas.**

   Suponga que $x_{1t}$ es $I(d_1)$ y $x_{2t}$ es $I(d_2)$ donde $d_2>d_1$ . Entonces, cualquier combinaciÃ³n lineal de $x_{1t}$ con $x_{2t}$ es $I(d_2)$.

   Sin embargo, **es posible encontrar relaciones de equilibrio entre grupos de variables que estÃ¡n integradas de diferentes Ã³rdenes.**

   Suponga que $x_{1t}$ y $x_{2t}$ son $I(2)$ y que las otras variables en consideraciÃ³n son $I(1)$. Como tal, no puede haber una relaciÃ³n de cointegraciÃ³n entre $x_{1t}$ (o $x_{2t}$) y $x_{3t}$. Sin embargo, si $x_{1t}$ y $x_{2t}$ son $CI(2,1)$, existe una combinaciÃ³n lineal de la forma $\beta_1x_{1t}+\beta_2x_{2t}$ que es $I(1)$, la cual es posible que estÃ© cointegrada con las variables $I(1)$.

[^3]: Tal falta de cointegraciÃ³n implica que no hay un equilibrio a largo plazo entre las variables, de modo que puedan desviarse arbitrariamente una de la otra.

3) **Puede haber mÃ¡s de un vector de cointegraciÃ³n independiente para un conjunto de variables $I(1)$.**[^4]

   Si $\mathbf{x_t}$ tiene $n$ componentes no estacionarios, puede haber hasta $n-1$ vectores de cointegraciÃ³n linealmente independientes. Por lo tanto, si $\mathbf{x_t}$ contiene solo dos variables, puede haber a lo sumo un vector de cointegraciÃ³n independiente.

[^4]: El nÃºmero de vectores de cointegraciÃ³n se denomina rango de cointegraciÃ³n del vector.

4) **La mayor parte de la literatura sobre cointegraciÃ³n se centra en el caso en el que cada variable tiene una sola raÃ­z unitaria.**

   La razÃ³n es que la regresiÃ³n tradicional o el anÃ¡lisis de series de tiempo se aplica cuando las variables son $I(0)$ y pocas variables econÃ³micas estÃ¡n integradas en un orden superior a $1$. 

Para terminar la explicaciÃ³n, en el siguiente grÃ¡fico se muestra una situaciÃ³n en la que tres variables $I(1)$ estan con cointegradas

![image](https://github.com/alvaroperdomo/World-Econometrics/assets/127871747/36a62b2e-6b7a-4643-8b77-507b154e0a5f)

Mientras que en este Ãºltimo grÃ¡fico se muestra una situaciÃ³n en la que dos variables $I(1)$ no estan con cointegradas

![image](https://github.com/alvaroperdomo/World-Econometrics/assets/127871747/4213813c-dae1-49b3-b6d7-f82180ac19fb)


## Pruebas de CointegraciÃ³n

Para el anÃ¡lisis de cointegraciÃ³n las metodologÃ­as mÃ¡s utilizadas son la de Engle y Granger (1987) y la de Johansen (1988)
 
### La MetodologÃ­a de Engle-Granger

Para explicar el procedimiento de prueba de Engle-Granger, comencemos con el tipo de problema que es usual en los estudios aplicados. Suponga que dos variables, digamos $y_t$ y $z_t$, son integradas de orden $1$ y se desea determinar si existe una relaciÃ³n de equilibrio entre las dos. Engle y Granger (1987) proponen un procedimiento de cuatro pasos para determinar si dos variables $I(1)$ estÃ¡n cointegradas de orden $CI(1,1)$:

1) **Haga una prueba preliminar de las variables para conocer su orden de integraciÃ³n.**
   
   Por definiciÃ³n, la cointegraciÃ³n requiere que dos variables estÃ©n integradas en el mismo orden. Por lo tanto, el primer paso en el anÃ¡lisis es determinar para cada variable su orden de integraciÃ³n.
     * Si ambas variables son estacionarias, no es necesario continuar ya que el mÃ©todo VAR se aplica a las variables estacionarias.
     * Si las variables estÃ¡n integradas de diferentes Ã³rdenes, se concluye que no estÃ¡n cointegradas.
     * Sin embargo, si tiene mÃ¡s de dos variables, de manera que algunas son $I(1)$ y otras son $I(2)$, es posible que desee determinar si las variables estÃ¡n cointegradas en forma mÃºltiple.

2) **Estime la relaciÃ³n del equilibrio a largo plazo.**

   Si los resultados indican que tanto { $y_t$ } como { $z_t$ } son $I(1)$, estime utilizando MÃ­nimos Cuadrados Ordinarios la relaciÃ³n de equilibrio: $y_t=\beta_0+\beta_1z_t+e_t$.

   Para determinar si las variables estÃ¡n realmente cointegradas, sea { $\hat{e_t}$ } la secuencia de residuos de esta ecuaciÃ³n. Por lo tanto, la serie { $\hat{e_t}$ } contiene los valores estimados de las desviaciones de la relaciÃ³n de largo plazo. Si se encuentra que estas desviaciones son estacionarias, las secuencias { $y_t$ } y { $z_t$ } son cointegradas de orden $(1,1)$. 

   SerÃ­a conveniente si si se pudiera realizar una prueba ADF de estos residuos para determinar su orden de integraciÃ³n. Considere la regresiÃ³n de los residuos: $\Delta\hat{e}=a_1\hat{e_{t-1}}+\varepsilon_t$ (dado que la secuencia { $\hat{e_t}$ } es el residuo de una regresiÃ³n, por lo que su media necesariamente igual a cero, entonces no es necesario incluir un intercepto dentro de la regresiÃ³n) donde el parÃ¡metro de interÃ©s es $a_1$:

   * Si no se puede rechazar la hipÃ³tesis nula $a_1=0$, se concluye que los residuos tienen una raÃ­z unitaria y por lo tanto, se deduce que las secuencias { $y_t$ } y { $z_t$ } no estÃ¡n cointegradas.
   * En cambio, el rechazo de la hipÃ³tesis nula implica que la secuencia de residuos es estacionaria. Si se encuentra que { $y_t$ } y { $z_t$ } son $I(1)$ y que los residuos son estacionarios, entonces se puede concluir que las series estÃ¡n cointegradas de orden $(1,1)$.

   En la mayorÃ­a de los estudios aplicados, no es posible utilizar las tablas de Dickey-Fuller. El problema es que la secuencia { $\hat{e_t}$ } se genera a partir de una regresiÃ³n; donde el investigador no conoce el error real $e_t$, solo el error estimado { $\hat{e_t}$ }.[^5]

[^5]: **Engle y Granger (1987) propusieron nuevas tablas para hacer los cÃ¡lculos. Y estas posteriormente fueron actualizadas por MacKinnon (1990). En estas tablas, los valores crÃ­ticos dependen del tamaÃ±o de la muestra y del nÃºmero de variables utilizadas en el anÃ¡lisis**

3) **Estime el vector de correcciÃ³n de errores**

   Si las variables estÃ¡n cointegradas, los residuos de la regresiÃ³n de equilibrio se pueden utilizar para estimar el vector de correcciÃ³n de errores ($VEC$). El $VEC$ es un $VAR$ en primeras diferencias, en donde las variables { $y_t$ } y { $z_t$ } son $CI(1,1)$, y se incluyen dentro del VEC de la siguiente forma:

   $I)$ $\Delta y_t = \alpha_1 + \alpha_y[y_{t-1}-\beta_1z_{t-1}]+\sum_{i=1}\alpha_{11}(i)\Delta y_{t-i}+\sum_{i=1}\alpha_{12}(i)\Delta z_{t-i}+\varepsilon_{yt}$

   $II)$ $\Delta z_t = \alpha_2 + \alpha_z[y_{t-1}-\beta_1z_{t-1}]+\sum_{i=1}\alpha_{21}(i)\Delta y_{t-i}+\sum_{i=1}\alpha_{22}(i)\Delta z_{t-i}+\varepsilon_{zt}$

   donde

   * $\beta_1$ es el parÃ¡metro del vector de cointegraciÃ³n dado por $y_t=\beta_0+\beta_1 z_t + e_t$ ğ‘¦_ğ‘¡=ğ›½_0+ğ›½_1 ğ‘§_ğ‘¡+ğ‘’_ğ‘¡;
   * $\varepsilon_{yt}$ y $\varepsilon_{zt}$ son  perturbaciones ruido blanco (que pueden estar corre-lacionadas entre sÃ­), y
   * $\alpha_1$, $\alpha_2$, $\alpha_y$, $\alpha_z$, $\alpha_{11}(i)$, $\alpha_{12}(i)$, $\alpha_{21}(i)$, $\alpha_{22}(i)$ son todos los parÃ¡metros.
   
   Engle y Granger (1987) proponen una forma de sortear las restricciones de ecuaciones cruzadas involucradas en la estimaciÃ³n directa de $I$ y $II$. La magnitud del residuo $\hat{e_{t-1}}$ es la desviaciÃ³n del equilibrio a largo plazo en el perÃ­odo {t-1}. Por lo tanto, es posible usar los residuos estimados { $\hat{e_{t-1}}$ }  obtenidos en el Paso 2 como una estimaciÃ³n de la expresiÃ³n $y_{t-1}-\beta_1z_{t-1}$ en $I$ y $II$. Por lo tanto, utilizando los $\hat{e_{t-1}}$ estime el VEC como:

   $i)$ $\Delta y_t = \alpha_1 + \alpha_y\hat{e_{t-1}}+\sum_{i=1}\alpha_{11}(i)\Delta y_{t-i}+\sum_{i=1}\alpha_{12}(i)\Delta z_{t-i}+\varepsilon_{yt}$

   $ii)$ $\Delta z_t = \alpha_2 + \alpha_z\hat{e_{t-1}}+\sum_{i=1}\alpha_{21}(i)\Delta y_{t-i}+\sum_{i=1}\alpha_{22}(i)\Delta z_{t-i}+\varepsilon_{zt}$

   Dado que la estructura del molelo $VEC$ es la de un $VAR$, entonces puede estimarse utilizando la misma metodologÃ­a desarrollada en la presentaciÃ³n de los modelos $VAR$. Dado que todas las variables en $i$ y $ii$ son estacionarias (es decir, $\Delta y_t$ y sus rezagos, $\Delta z_t$ y sus rezagos, y $\hat{e_{t-1}}$ son $I(0)$), los estadÃ­sticos de prueba utilizados en el anÃ¡lisis $VAR$ tradicional son apropiados para $i$ y $ii$. 

4) **Evaluar la adecuaciÃ³n del modelo**

   Hay varios procedimientos que pueden ayudar a determinar si el $VEC$ es apropiado:

   a) **Realice verificaciones de diagnÃ³stico para determinar si los residuos de las ecuaciones de correcciÃ³n de errores se aproximan al ruido blanco**.

   Si los residuos estÃ¡n serialmente correlacionados, las longitudes de los rezagos pueden ser demasiado cortas. Vuelva a estimar el modelo utilizando longitudes de rezago que produzcan errores que no estÃ¡n serialmente correlacionados.

   b) **La velocidad de ajuste de los coeficientes $\alpha_y$  y $\alpha_z$  son de particular interÃ©s, ya que tienen implicaciones importantes para la dinÃ¡mica del sistema.**

   Los valores de $\alpha_y$ y $\alpha_z$ estÃ¡n directamente relacionados con las raÃ­ces caracterÃ­sticas del sistema de ecuaciones en diferencias. La convergencia directa requiere $\alpha_y$  que sea negativo y que $\alpha_z$  sea positivo.

   Si nos centramos en $ii$, para cualquier valor dado de $\hat{e_{t-1}}$,
   * un gran valor de $\alpha_z$ se asocia con un gran valor de $\Delta z_t$. 
   * Si $\alpha_z=0$ , el $\Delta z_t$  no responde en absoluto a $\hat{e_{t-1}}$. 
   * Si $\alpha_z=0$ y si todos los $\alpha_{21}=0$, entonces se puede decir que { $\Delta y_t$ } no causa en el sentido de Granger a { $\Delta z_t$ } .
   
     Sabemos que $\alpha_y$ y/o $\alpha_z$ deberÃ­an ser significativamente diferentes de cero si las variables estÃ¡n cointegradas. DespuÃ©s de todo, si $\alpha_y=\alpha_z=0$, no hay correcciÃ³n de errores y $i$ y $ii$ serÃ­an nada mÃ¡s que un $VAR$ en las primeras diferencias. AdemÃ¡s, los valores absolutos de estas velocidades de ajuste de los coeficientes no deben ser demasiado grandes. Las estimaciones puntuales deberÃ­an implicar que $\Delta y_t$ y $\Delta z_t$ convergen a la relaciÃ³n de equilibrio a largo plazo.

     c) **Al igual que en un anÃ¡lisis $VAR$ tradicional, Lutkepohl y Reimers (1992) muestran que el anÃ¡lisis de los impulso-respuesta y la descomposiciÃ³n de varianza se puede utilizar para obtener informaciÃ³n sobre las interacciones entre las variables.**

     Como cuestiÃ³n prÃ¡ctica, las dos innovaciones $\varepsilon_{yt}$  y $\varepsilon_{zt}$  pueden correlacionarse simultÃ¡neamente si $y_t$ tiene un efecto contemporÃ¡neo en $z_t$ y/o si $z_t$ tiene un efecto contemporÃ¡neo en $y_t$. Para obtener funciones impulso-respuesta y las descomposiciones de varianza, se debe utilizar algÃºn mÃ©todo, como la descomposiciÃ³n de Choleski, para ortogonalizar las innovaciones. La forma de las funciones impulso-respuesta y los resultados de las descomposiciones de varianza pueden indicar si las respuestas dinÃ¡micas de las variables se ajustan a la teorÃ­a. Como todas las variables en $i$ y $ii$ son $I(0)$, los impulso-respuesta de $\Delta y_t$ y $\Delta z_t$ deben converger a cero.[^3]

     Es tentador utilizar estadÃ­sticos $t$ para realizar pruebas de significancia en el vector de cointegraciÃ³n. Sin embargo, debe evitar esta tentaciÃ³n ya que, en general, los coeficientes no tienen una distribuciÃ³n $t$ asintÃ³tica.
     
[^3]: **Debe reexaminar los resultados de cada paso si obtiene una funciÃ³n de impulso-respuesta explosiva o que no decae.**

### Inconvenientes con la MetodologÃ­a de Engle-Granger
Aunque el procedimiento de Engle y Granger (1987) se implementa fÃ¡cilmente, tiene varios defectos importantes. 

1) La estimaciÃ³n de la regresiÃ³n de equilibrio a largo plazo requiere que el investigador coloque una variable en el lado izquierdo y utilice las otras variables como regresores. 

Por ejemplo, en el caso de dos variables, es posible hacer la prueba de cointegraciÃ³n de Engle-Granger utilizando los residuos de cualquiera de las siguientes dos regresiones de "equilibrio":

   * $y_t=\beta_{10}+\beta_{11}z_t+e_{1t}$  o
   * $y_t=\beta_{20}\beta_{21}y_t+e_{2t}$      

A medida que el tamaÃ±o de la muestra crece hacia infinito, la teorÃ­a asintÃ³tica indica que la prueba de raÃ­z unitaria en la secuencia { $e_{1t}$ } se vuelve equivalente a la prueba de raÃ­z unitaria en la secuencia { $e_{2t}$ } . Desafortunadamente, las propiedades de muestras grandes que obtienen este resultado pueden no ser aplicables a los tamaÃ±os de muestra generalmente disponibles. En la prÃ¡ctica, es posible encontrar que una regresiÃ³n implique que las variables estÃ¡n cointegradas, mientras que revertir el orden implique que no hay cointegraciÃ³n. Esta es una caracterÃ­stica muy indeseable del procedimiento porque la prueba de cointegraciÃ³n debe ser invariable a la elecciÃ³n de la variable seleccionada para la normalizaciÃ³n. El problema se agrava utilizando tres o mÃ¡s variables, ya que cualquiera de las variables puede seleccionarse como la variable del lado izquierdo. AdemÃ¡s, en las pruebas que usan tres o mÃ¡s variables, sabemos que puede haber mÃ¡s de un vector de cointegraciÃ³n. El mÃ©todo de Engle-Granger no tiene un proce-dimiento sistemÃ¡tico para la estimaciÃ³n separada de los mÃºltiples vectores de coin-tegraciÃ³n

2) Otro defecto del procedimiento de Engle-Granger es que se basa en un estimador de dos pasos.

El primer paso es generar la serie de residuos $\hat{e_t}$, y el segundo paso utiliza estos errores generados para estimar una regresiÃ³n de la forma $\Delta\hat{e_t}=a_1\Delta\hat{e_{t-1}}+\dots$ Entonces, el coeficiente $a_1$ se obtiene estimando una regresiÃ³n que utiliza los residuos de otra regresiÃ³n. Por lo tanto, cualquier error introducido por el investigador en el Paso $i$ se lleva al Paso $ii$. 

### La MetodologÃ­a de Johansen

Los estimadores de mÃ¡xima verosimilitud de Johansen (1988) evitan el uso de estimadores de dos pasos y pueden estimar y probar la presencia de mÃºltiples vectores de cointegraciÃ³n. AdemÃ¡s, estas pruebas permiten probar versiones restringidas de los vectores de cointegraciÃ³n y la velocidad de los parÃ¡metros de ajuste.[^3] 

[^3]: **A menudo, es interesante determinar si es posible verificar una teorÃ­a probando restricciones en las magnitudes de los coeficientes estimados**

El procedimiento de Johansen (1988) se basa en gran medida en la relaciÃ³n entre el rango de una matriz y sus raÃ­ces caracterÃ­sticas. Este no es mÃ¡s que una generalizaciÃ³n multivariada de la prueba $DF$. En el caso univariado, es posible ver que la estacionariedad de { $y_t$ } depende de $a_1$; es decir, dados $y_t=a_1y_{t-1}+\varepsilon_t$ o $\Delta y_t=(a_1-1)y_{t-1}+\varepsilon_t$. Si $(a_1-1)=0$, el proceso { $y_t$ } tiene una raÃ­z unitaria. Descartando el caso en el que { $y_t$ } es explosivo, si $(a_1-1)â‰ 0$ podemos concluir que la secuencia { $y_t$ } es estacionaria. Las tablas de Dickey-Fuller proporcionan los estadÃ­sticos apropiados para probar formalmente la hipÃ³tesis nula $(a_1-1)=0$.

Consideremos la generalizaciÃ³n al caso simple con ğ‘› variables; asuma que el vector $x_t$ de $n$ variables, se comporta como $x_t=A_1x_{t-1}+\varepsilon_t$  asÃ­ que $\Delta x_t=A_1x_{t-1}-x_{t-1}+\varepsilon_t=(A_1-I)x_{t-1}+\varepsilon_t=\pi x_t-1+\varepsilon_t$ donde 
* $\varepsilon_t$ es un vector ( $n\times 1$ ),
* $A_1$ es una matriz ( $n\times n$ ) de parÃ¡metros, 
* $I$ es una matriz identidad ( $n\times n$ ), 
ğœ‹ se define como (ğ´_1âˆ’ğ¼).
El rango de (ğ´_1âˆ’ğ¼) es igual al nÃºmero de vectores de cointegraciÃ³n. 
Por analogÃ­a con el caso univariado, si (ğ´_1âˆ’ğ¼)  tiene solo ceros, de modo que el ğ‘Ÿğ‘ğ‘›ğ‘”ğ‘œ(ğœ‹)=0, todas las secuencias {ğ‘¥_ğ‘–ğ‘¡} son raÃ­z unitaria. 
En esta situaciÃ³n, dado que no hay una combinaciÃ³n lineal de los procesos {ğ‘¥_ğ‘–ğ‘¡} que sea estacio-naria, las variables no se cointegran. 
Descartando la presencia de raÃ­ces caracterÃ­sticas mayores que 1 y si el ğ‘Ÿğ‘ğ‘›ğ‘”ğ‘œ(ğœ‹)=ğ‘›, âˆ†ğ‘¥_ğ‘¡=ğœ‹ğ‘¥_(ğ‘¡âˆ’1)+ğœ€_ğ‘¡ es un sistema convergente de ecuacio-nes en diferencias, de modo que todas las variables son estacionarias.












