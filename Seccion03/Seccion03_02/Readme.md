# Estimaci√≥n de Modelos VAR
Si se quiere tener en cuenta todas las relaciones posibles entre, digamos, $k$ variables, parece sensato construir un modelo conjunto para todas estas series de tiempo en lugar de construir modelos para todas las series individuales. 

Considere el sistema bivariado simple:

$I$) $y_t=b_{10}-b_{12}z_t+\gamma_{11}y_{t-1}+\gamma_{12}z_{t-1}+\varepsilon_{yt}$  

$II$) $z_t=b_{20}-b_{21}y_t+\gamma_{21}y_{t-1}+\gamma_{22}z_{t-1}+\varepsilon_{zt}$   

donde se supone que 
* tanto $y_t$ como $z_t$ son estacionarios; 
* $\varepsilon_{yt}$  y $\varepsilon_{zt}$ son perturbaciones ruido blanco con desviaciones est√°ndar $\sigma_y$  y $\sigma_z$, respectivamente; y 
* { $\varepsilon_{yt}$ } y { $\varepsilon_{zt}$ } son perturbaciones ruido blanco no correlacionadas.

Las ecuaciones $I$ y $II$ constituyen un vector autorregresivo de primer orden ($VAR$) porque la longitud de rezago m√°s larga es $1$ [^1]. La estructura del sistema incorpora retroalimentaci√≥n porque permite que $y_t$ y $z_t$ se afecten entre s√≠. Por ejemplo, $-b_{12}$  es el efecto contempor√°neo de un cambio unitario de $z_t$ en $y_t$ y $\gamma_{12}$  es el efecto de un cambio de unitario de $z_{t-1}$ en $y_t$. 

[^1]: **Este _VAR_ sencillo es √∫til para ilustrar los sistemas multivariados de orden superior que se presentaran m√°s adelante.**

Tenga en cuenta que los t√©rminos { $\varepsilon_{yt}$ y $\varepsilon_{zt}$  son innovaciones puras (o choques) en $y_t$ y $z_t$, respectivamente. Por supuesto, 
* si $b_{21}‚â†0$, $\varepsilon_{yt}$  tiene un efecto contempor√°neo indirecto en $z_t$, y
* si $b_{12}‚â†0$, $\varepsilon_{zt}$  tiene un efecto contempor√°neo indirecto en $y_t$. 

Las ecuaciones $I$ y $II$ no pueden ser estimadas por MCO ya que $y_t$ tiene un efecto contempor√°neo en $z_t$ y $z_t$ tiene un efecto contempor√°neo en $y_t$. Las estimaciones de MCO sufrir√≠an un sesgo de simultaneidad ya que los regresores y los t√©rminos de error estar√≠an correlacionados.

Es posible transformar el sistema de ecuaciones en una forma compacta:

$$Bx_t= \Gamma_0 + \Gamma_1x_{t-1}+\varepsilon_t$$ 

donde $\eqalign{B = {\left\lbrack \matrix{1 & b_{12} \cr b_{21} & 1} \right\rbrack}}$, $\eqalign{x_t = {\left\lbrack \matrix{y_t \cr z_t} \right\rbrack}}$, $\eqalign{\Gamma_0 = {\left\lbrack \matrix{b_{10} \cr b_{20}} \right\rbrack}}$, $\eqalign{\Gamma_1 = {\left\lbrack \matrix{\gamma_{11} & \gamma_{12} \cr \gamma_{21} & \gamma_{22}} \right\rbrack}}$ y $\eqalign{\varepsilon_t = {\left\lbrack \matrix{\varepsilon_{yt} \cr \varepsilon_{zt}} \right\rbrack}}$

Al premultiplicar por $B^{‚àí1}$ se obtiene el **modelo VAR en forma est√°ndar** $x_t= A_0 + A_1x_{t-1}+e_t$  donde $A_0=B^{‚àí1}\Gamma_0$, $A_1=B^{‚àí1}\Gamma_1$, y $e_t=B^{‚àí1}\varepsilon_t$

Por prop√≥sitos de notaci√≥n, podemos definir
* $a_{i0}$  como el elemento $i$ del vector $A_0$,
* $a_{ij}$ como el elemento en la fila $i$ y la columna $j$ de la matriz $A_1$, y
* $e_{it}$ como el elemento $i$ del vector $e_t$. 

Usando esta nueva notaci√≥n, podemos reescribir $x_t= A_0 + A_1x_{t-1}+e_t$ en la forma equivalente:

$i$) $y_t=a_{10}+a_{11}y_{t-1}+a_{12}z_{t-1}+e_{1t}$ 

$ii$) $z_t=a_{20}+a_{21}y_{t-1}+a_{22}z_{t-1}+e_{2t}$

Para distinguir entre los sistemas representados por $I$ y $II$ versus $i$ y $ii$, el primero se llama un **VAR estructural o sistema primitivo** y el segundo se llama un **VAR en forma est√°ndar**. 

Es importante tener en cuenta que los t√©rminos de error (es decir, $e_{1t}$ y $e_{2t}$) son compuestos de los dos choques $\varepsilon_{yt}$  y $\varepsilon_{zt}$. Y se puede demostrar, aunque aqu√≠ no lo desarrollaremos, que dado que como $\varepsilon_{yt}$  y $\varepsilon_{zt}$ son procesos de ruido blanco, entonces $e_{1t}$ y $e_{2t}$ son ruido blanco

Un objetivo expl√≠cito del enfoque de Box-Jenkins es proporcionar una metodolog√≠a que conduzca a modelos parsimoniosos. El objetivo final de hacer pron√≥sticos precisos a corto plazo se logra mejor eliminando las estimaciones de par√°metros insignificantes del modelo. 

Sims (1980) aboga por una estrategia de estimaci√≥n alternativa. 

Considere la siguiente generalizaci√≥n multivariada de un proceso autorregresivo $x_t= A_0 + A_1x_{t-1}+...+A_px_{t-p}+e_t$ donde 
* $x_t$ es un vector ($n√ó1$) que re√∫ne las ùëõ variables incluidas en el $VAR$
* $A_0$ es un vector ($n√ó1$) de interceptos
* $A_i$ son las matrices ($n√ón$) de coeficientes
* $e_t$ es un vector ($n√ó1$) de los t√©rminos de error

La metodolog√≠a de Sims implica √∫nicamente:
1) la determinaci√≥n de las variables apropiadas para incluir en el $VAR$: Las variables que se incluir√°n en el $VAR$ se seleccionan de acuerdo con el modelo econ√≥mico relevante.
2) la determinaci√≥n de la longitud de rezagos apropiada: Existen una serie de pruebas (las cuales se explicar√°n m√°s adelante) para hacer esto. No se hace un intento expl√≠cito de "reducir" el n√∫mero de par√°metros estimados. La matriz $A_0$ contiene $n$ par√°metros, y cada matriz $A_i$ contiene $n^2$ par√°metros; por lo tanto, $n+pn^2$ coeficientes deben ser estimados. 

Sin lugar a dudas, el $VAR$ esta sobreparameterizado ya que muchas de las estimaciones de los coeficientes ser√°n no significativas. Sin embargo, el objetivo es encontrar las interrelaciones importantes entre las variables. Imponer incorrectamente restricciones nulas puede desperdiciar informaci√≥n importante. Adem√°s, es probable que los regresores sean altamente colineales, de modo que las pruebas $t$ sobre los coeficientes individuales no son gu√≠as confiables para reducir el modelo.

## Pron√≥sticos
Una vez que se ha estimado el $VAR$, se puede utilizar como un modelo de pron√≥stico de m√∫ltiples ecuaciones. 

Suponga que estima el modelo de primer orden $x_t=A_0+A_1x_{t-1}+e_t$ para obtener los valores de los coeficientes en $A_0$ y $A_1$. Si sus datos van hasta el per√≠odo $T$, es sencillo obtener los pron√≥sticos de un periodo hacia adelante de sus variables utilizando la relaci√≥n $E_Tx_{T+1}=A_0+A_1x_T$. De manera similar, se puede obtener un pron√≥stico de dos periodos hacia adelante utilizando la relaci√≥n $E_Tx_{T+2}=A_0+A_1x_{T+1}=A_0+A_1(A_0+A_1x_T)$. Sin embargo, en un modelo de orden superior, puede haber un gran n√∫mero de coeficientes estimados. Dado que los ùëâùê¥ùëÖ no restringidos est√°n sobreparametrizados, los pron√≥sticos pueden ser poco confiables. Con el fin de obtener un modelo parsimonioso, muchos pronosticadores eliminar√≠an los coeficientes no significativos del $VAR$. Para despu√©s volver a estimar el modelo llamado $near-VAR$ mediante el uso de un $SUR$, para utilizar con fines de pron√≥stico. 

## La Funci√≥n Impulso-Respuesta
Al igual que un proceso autorregresivo tiene una representaci√≥n de media m√≥vil, un $VAR$ puede escribirse como un vector de media m√≥vil ($VMA$). 
$\eqalign{x_t=\mu+\sum_{i=1}^p A_1^i e_{t-i}}$ es la representaci√≥n $VMA$ de $x_t=A_0+A_1x_{t-1}+e_t$  en donde las variables (es decir, $y_t$ y $z_t$) se expresan en t√©rminos de los valores actuales y pasados de los dos tipos de choques (es decir, $e_{1t}$ y $e_{2t}$).[^2] 
[^2]: **La representaci√≥n $VMA$ es una caracter√≠stica esencial de la metodolog√≠a de Sims (1980), ya que permite rastrear la trayectoria en el tiempo de los diversos choques de las variables contenidas en el sistema _VAR_**. 

Para fines ilustrativos, usaremos el modelo de primer orden de dos variables analizado previamnete. Escribiendo el $VAR$ de dos variables en forma matricial, ${\left\lbrack \matrix{y_t \cr z_t} \right\rbrack} = {\left\lbrack \matrix{a_{10} \cr a_{20}} \right\rbrack} + {\left\lbrack \matrix{a_{11} & a_{12} \cr a_{21} & a_{22}}\right\rbrack}{\left\lbrack \matrix{y_{t-1} \cr z_{t-1}} \right\rbrack}+{\left\lbrack \matrix{e_{1t} \cr e_{2t}} \right\rbrack}$ o usando $\eqalign{x_t=\mu+\sum_{i=1}^p A_1^i e_{t-i}}$ tenemos $\eqalign{{\left\lbrack \matrix{y_t \cr z_t} \right\rbrack} = {\left\lbrack \matrix{\overline{y} \cr \overline{z}} \right\rbrack} + \sum_{i=0}^\infty{\left\lbrack \matrix{a_{11} & a_{12} \cr a_{21} & a_{22}}\right\rbrack}^i+{\left\lbrack \matrix{e_{1(t-i)} \cr e_{2(t-i)}} \right\rbrack}}$.

Esta ecuaci√≥n expresa $y_t$ y $z_t$ en t√©rminos de las secuencias $e_{1t}$ y $e_{2t}$. Sin embargo, si se reescriben en t√©rminos de las secuencias $\varepsilon_{yt}$ y $\varepsilon_{zt}$, se obtiene: $\eqalign{{\left\lbrack \matrix{y_t \cr z_t} \right\rbrack} = {\left\lbrack \matrix{\overline{y} \cr \overline{z}} \right\rbrack} + \sum_{i=0}^\infty{\left\lbrack \matrix{\phi_{11}(i) & \phi_{12}(i) \cr \phi_{21}(i) & \phi_{22}(i)}\right\rbrack}^i+{\left\lbrack \matrix{\varepsilon_{y(t-i)} \cr \varepsilon_{z(t-i)}} \right\rbrack}}$ donde $\phi_i=\frac{A_1^i}{1-b_{12}b_{21}}{\left\lbrack \matrix{1 & -b_{12} \cr -b_{21} & 1}\right\rbrack}$ o en forma m√°s compacta, $\eqalign{x_t=\mu+\sum_{i=1}^\infty \phi_i \varepsilon_{t-i}}$

La representaci√≥n de la media m√≥vil es una herramienta especialmente √∫til para examinar la interacci√≥n entre las secuencias { $y_t$ } y { $z_t$ }. 
Los coeficientes de $\phi_i$  se pueden usar para generar los efectos de los choques $\varepsilon_{yt}$  y $\varepsilon_{zt}$  en las trayectorias temporales de las secuencias { $y_t$ } y { $z_t$ }: 

1) Los cuatro elementos $\phi_{jk}(0)$ son **multiplicadores de impacto**. Por ejemplo, el coeficiente $\phi_{12}(0)$ es el impacto instant√°neo de un cambio en una unidad de $\varepsilon_{zt}$ en $y_t$. 
2) De la misma manera, los elementos $\phi_{12}(1)$ y $\phi_{12}(1)$ son las respuestas en el siguiente per√≠odo de los cambios unitarios de $\varepsilon_{y(t-1)}$ y $\varepsilon_{z(t-1)}$ en $y_t$, respectivamente. La actualizaci√≥n un per√≠odo hac√≠a adelante tambi√©n indica que $\phi_{12}(1)$ y $\phi_{12}(1)$ representan los efectos de los cambios unitarios de $\varepsilon_{yt}$ y $\varepsilon_{zt}$ en $y_{t+1}$.

Los efectos acumulados de los impulsos unitarios en $\varepsilon_{yt}$  y/o $\varepsilon_{zt}$  se pueden obtener mediante la suma apropiada de los coeficientes de las funciones de impulso-respuesta. Por ejemplo, tenga en cuenta que, despu√©s de $n$ periodos, el efecto de $\varepsilon_{zt}$  en el valor de $y_{t+n}$ es $\phi_{12}(n)$. Por lo tanto, despu√©s de $n$ periodos, la suma acumulada de los efectos de $\varepsilon_{zt}$  en la secuencia { $y_t$ } es $\eqalign{\sum_{i=0}^n \phi_{12}(i)}$

Cuando $n$ se aproxima al infinito se produce el efecto total acumulado. Si se supone que las secuencias { $y_t$ } y { $z_t$ } son estacionarias, debe darse el caso de que para todos los $j$ y $k$, los valores de $\phi_{12}(i)$ convergen a cero a medida que $i$ se hace grande. Esto ocurre porque los choques no pueden tener un efecto permanente en una serie estacionaria. 


. 











