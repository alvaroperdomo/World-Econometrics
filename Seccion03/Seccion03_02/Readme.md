# Estimaci√≥n de Modelos de Vectores Autorregresivos $VAR$
Si se quiere tener en cuenta todas las relaciones posibles entre, digamos, $k$ variables, parece sensato construir un modelo conjunto que incluya todas estas series de tiempo en lugar de construir modelos para cada una de las series individuales. 

Considere el sistema bivariado simple[^1]:

[^1]: **Por razones pedag√≥gicas nos centraremos principalemente en el an√°lisis de este sistema _VAR_ dos variables. Este _VAR_ sencillo es √∫til para ilustrar los sistemas multivariados de orden superior que se presentaran m√°s adelante**

$I$) $y_t=b_{10}-b_{12}z_t+\gamma_{11}y_{t-1}+\gamma_{12}z_{t-1}+\varepsilon_{yt}$  

$II$) $z_t=b_{20}-b_{21}y_t+\gamma_{21}y_{t-1}+\gamma_{22}z_{t-1}+\varepsilon_{zt}$   

donde se supone que 
* tanto { $y_t$ } como { $z_t$ } son series estacionarias; 
* { $\varepsilon_{yt}$ }  y { $\varepsilon_{zt}$ } son perturbaciones ruido blanco con desviaciones est√°ndar $\sigma_y$  y $\sigma_z$, respectivamente; y 
* { $\varepsilon_{yt}$ } y { $\varepsilon_{zt}$ } son perturbaciones ruido blanco no correlacionadas.

Las ecuaciones $I$ y $II$ constituyen un vector autorregresivo de primer orden $VAR(1)$ porque la longitud de rezago m√°s larga es $1$. La estructura del sistema incorpora retroalimentaci√≥n porque permite que $y_t$ y $z_t$ se afecten entre s√≠. Por ejemplo, $-b_{12}$  es el efecto contempor√°neo de un cambio unitario de $z_t$ en $y_t$ y $\gamma_{12}$ es el efecto de un cambio de unitario de $z_{t-1}$ en $y_t$. 

Tenga en cuenta que los t√©rminos $\varepsilon_{yt}$ y $\varepsilon_{zt}$ son innovaciones puras (o choques) en $y_t$ y $z_t$, respectivamente. Por supuesto, 
* si $b_{21}‚â†0$, $\varepsilon_{yt}$  tiene un efecto contempor√°neo indirecto en $z_t$, y
* si $b_{12}‚â†0$, $\varepsilon_{zt}$  tiene un efecto contempor√°neo indirecto en $y_t$. 

Las ecuaciones $I$ y $II$ no pueden ser estimadas por M√≠nimos Cuadrados Ordinarios ( $MCO$ ) ya que 
* $y_t$ tiene un efecto contempor√°neo en $z_t$ y
* $z_t$ tiene un efecto contempor√°neo en $y_t$.

Por lo tanto, las estimaciones de $MCO$ sufrir√≠an un sesgo de simultaneidad ya que los regresores y los t√©rminos de error estar√≠an correlacionados.

Es posible transformar el sistema de ecuaciones en una forma compacta: $\mathbf{B x_t= \Gamma_0 + \Gamma_1 x_{t-1}+\varepsilon_t}$

donde $\eqalign{\mathbf{B} = {\left\lbrack \matrix{1 & b_{12} \cr b_{21} & 1} \right\rbrack}}$, $\eqalign{\mathbf{x_t} = {\left\lbrack \matrix{y_t \cr z_t} \right\rbrack}}$, $\eqalign{\mathbf{\Gamma_0}= {\left\lbrack \matrix{b_{10} \cr b_{20}} \right\rbrack}}$, $\eqalign{\mathbf{\Gamma_1} = {\left\lbrack \matrix{\gamma_{11} & \gamma_{12} \cr \gamma_{21} & \gamma_{22}} \right\rbrack}}$ y $\eqalign{\mathbf{\varepsilon_t} = {\left\lbrack \matrix{\varepsilon_{yt} \cr \varepsilon_{zt}} \right\rbrack}}$

Al premultiplicar por $\mathbf{B^{‚àí1}}$ se obtiene el **modelo VAR en forma est√°ndar** $\mathbf{x_t= A_0 + A_1x_{t-1}+e_t}$  donde $\mathbf{A_0=B^{‚àí1}\Gamma_0}$, $\mathbf{A_1=B^{‚àí1}\Gamma_1}$, y $\mathbf{e_t=B^{‚àí1}\varepsilon_t}$

Por prop√≥sitos de notaci√≥n, podemos definir
* $a_{i0}$  como el elemento $i$ del vector $\mathbf{A_0}$,
* $a_{ij}$ como el elemento en la fila $i$ y la columna $j$ de la matriz $\mathbf{A_1}$, y
* $e_{it}$ como el elemento $i$ del vector $\mathbf{e_t}$. 

Usando esta nueva notaci√≥n, podemos reescribir $\mathbf{x_t= A_0 + A_1x_{t-1}+e_t}$ en la forma equivalente:

$i$) $y_t=a_{10}+a_{11}y_{t-1}+a_{12}z_{t-1}+e_{1t}$ 

$ii$) $z_t=a_{20}+a_{21}y_{t-1}+a_{22}z_{t-1}+e_{2t}$

Para distinguir entre los sistemas representados por $I$ y $II$ versus $i$ y $ii$, el primero se llama un **VAR estructural o sistema primitivo** y el segundo se llama un **VAR en forma est√°ndar**. 

Es importante tener en cuenta que los t√©rminos de error (es decir, $e_{1t}$ y $e_{2t}$) son compuestos de los dos choques $\varepsilon_{yt}$  y $\varepsilon_{zt}$. Y se puede demostrar, aunque aqu√≠ no lo desarrollaremos, que dado que como $\varepsilon_{yt}$  y $\varepsilon_{zt}$ son procesos de ruido blanco, entonces $e_{1t}$ y $e_{2t}$ son ruido blanco

Un objetivo expl√≠cito del enfoque de Box-Jenkins es proporcionar una metodolog√≠a que conduzca a modelos parsimoniosos. El objetivo final de hacer pron√≥sticos precisos a corto plazo se logra mejor eliminando las estimaciones de par√°metros insignificantes del modelo. 

Sims (1980) aboga por una estrategia de estimaci√≥n alternativa. 

Considere la siguiente generalizaci√≥n multivariada de un proceso autorregresivo $\mathbf{x_t=A_0 +  A_1x_{t-1} + \dots + A_p x_{t-p} + e_t}$ donde 
* $\mathbf{x_t}$ es un vector ($n \times 1$) que re√∫ne las ùëõ variables incluidas en el $VAR$
* $\mathbf{A_0}$ es un vector ($n \times 1$) de interceptos
* $\mathbf{A_i}$ son las matrices ($n \times n$) de coeficientes
* $\mathbf{e_t}$ es un vector ($n \times 1$) de los t√©rminos de error

La metodolog√≠a de Sims implica √∫nicamente:
1) la determinaci√≥n de las variables apropiadas para incluir en el $VAR$: Las variables que se incluir√°n en el $VAR$ se seleccionan de acuerdo con el modelo econ√≥mico relevante.
2) la determinaci√≥n de la longitud de rezagos apropiada: Existen una serie de pruebas (las cuales se explicar√°n m√°s adelante) para hacer esto. No se hace un intento expl√≠cito de "reducir" el n√∫mero de par√°metros estimados. La matriz $\mathbf{A_0}$ contiene $n$ par√°metros, y cada matriz $\mathbf{A_i}$ contiene $n^2$ par√°metros; por lo tanto, $n+pn^2$ coeficientes deben ser estimados. 

Sin lugar a dudas, el $VAR$ esta sobreparameterizado ya que muchas de las estimaciones de los coeficientes ser√°n no significativas. Sin embargo, el objetivo es encontrar las interrelaciones importantes entre las variables. Imponer incorrectamente restricciones nulas puede desperdiciar informaci√≥n importante. Adem√°s, es probable que los regresores sean altamente colineales, de modo que las pruebas $t$ sobre los coeficientes individuales no son gu√≠as confiables para reducir el modelo.

De todas formas, 

## Pron√≥sticos
Una vez que se ha estimado el $VAR$, se puede utilizar como un modelo de pron√≥stico de m√∫ltiples ecuaciones. 

Suponga que estima el modelo de primer orden $\mathbf{x_t=A_0+A_1x_{t-1}+e_t}$ para obtener los valores de los coeficientes en $\mathbf{A_0}$ y en $\mathbf{A_1}$. Si sus datos van hasta el per√≠odo $T$, es sencillo obtener los pron√≥sticos de un periodo hacia adelante de sus variables utilizando la relaci√≥n $E_T\mathbf{x_{T+1}=A_0+A_1x_T}$. De manera similar, se puede obtener un pron√≥stico de dos periodos hacia adelante utilizando la relaci√≥n $E_T\mathbf{x_{T+2}=A_0+A_1x_{T+1}=A_0+A_1(A_0+A_1x_T)}$. 

Sin embargo, en un modelo de orden superior, puede haber un gran n√∫mero de coeficientes estimados. Dado que los ùëâùê¥ùëÖ no restringidos est√°n sobreparametrizados, los pron√≥sticos pueden ser poco confiables. Con el fin de obtener un modelo parsimonioso, muchos pronosticadores eliminar√≠an los coeficientes no significativos del $VAR$. Para despu√©s volver a estimar el modelo llamado $near-VAR$ mediante el uso de un $SUR$, para utilizar con fines de pron√≥stico. 

## La Funci√≥n Impulso-Respuesta
Al igual que un proceso autorregresivo tiene una representaci√≥n de media m√≥vil, un $VAR$ puede escribirse como un vector de media m√≥vil ($VMA$). 

$\eqalign{\mathbf{x_t=\mu+\sum_{i=1}^p A_1^i e_{t-i}}}$ es la representaci√≥n $VMA$ de $\mathbf{x_t=A_0+A_1x_{t-1}+e_t}$  en donde las variables (es decir, $y_t$ y $z_t$) se expresan en t√©rminos de los valores actuales y pasados de los dos tipos de choques (es decir, $e_{1t}$ y $e_{2t}$).[^2] 

[^2]: **La representaci√≥n _VMA_ es una caracter√≠stica esencial de la metodolog√≠a de Sims (1980), ya que permite rastrear la trayectoria en el tiempo de los diversos choques de las variables contenidas en el sistema _VAR_**. 

Para fines ilustrativos, usaremos el modelo de primer orden de dos variables analizado previamente. Escribiendo el $VAR$ de dos variables en forma matricial, ${\left\lbrack \matrix{y_t \cr z_t} \right\rbrack} = {\left\lbrack \matrix{a_{10} \cr a_{20}} \right\rbrack} + {\left\lbrack \matrix{a_{11} & a_{12} \cr a_{21} & a_{22}}\right\rbrack}{\left\lbrack \matrix{y_{t-1} \cr z_{t-1}} \right\rbrack}+{\left\lbrack \matrix{e_{1t} \cr e_{2t}} \right\rbrack}$ o usando $\eqalign{\mathbf{x_t=\mu+\sum_{i=1}^p A_1^i e_{t-i}}}$ tenemos $\eqalign{{\left\lbrack \matrix{y_t \cr z_t} \right\rbrack} = {\left\lbrack \matrix{\overline{y} \cr \overline{z}} \right\rbrack} + \sum_{i=0}^\infty{\left\lbrack \matrix{a_{11} & a_{12} \cr a_{21} & a_{22}}\right\rbrack}^i+{\left\lbrack \matrix{e_{1(t-i)} \cr e_{2(t-i)}} \right\rbrack}}$.

Esta ecuaci√≥n expresa $y_t$ y $z_t$ en t√©rminos de las secuencias $e_{1t}$ y $e_{2t}$. Sin embargo, si se reescriben en t√©rminos de las secuencias $\varepsilon_{yt}$ y $\varepsilon_{zt}$, se obtiene: $\eqalign{{\left\lbrack \matrix{y_t \cr z_t} \right\rbrack} = {\left\lbrack \matrix{\overline{y} \cr \overline{z}} \right\rbrack} + \sum_{i=0}^\infty{\left\lbrack \matrix{\phi_{11}(i) & \phi_{12}(i) \cr \phi_{21}(i) & \phi_{22}(i)}\right\rbrack}^i+{\left\lbrack \matrix{\varepsilon_{y(t-i)} \cr \varepsilon_{z(t-i)}} \right\rbrack}}$ donde $\phi_i=\frac{A_1^i}{1-b_{12}b_{21}}{\left\lbrack \matrix{1 & -b_{12} \cr -b_{21} & 1}\right\rbrack}$ o en forma m√°s compacta, $\eqalign{\mathbf{x_t=\mu+\sum_{i=1}^\infty \phi_i \varepsilon_{t-i}}}$

La representaci√≥n de la media m√≥vil es una herramienta especialmente √∫til para examinar la interacci√≥n entre las secuencias { $y_t$ } y { $z_t$ }. 
Los coeficientes de $\phi_i$  se pueden usar para generar los efectos de los choques $\varepsilon_{yt}$  y $\varepsilon_{zt}$  en las trayectorias temporales de las secuencias { $y_t$ } y { $z_t$ }: 

1) Los cuatro elementos $\phi_{jk}(0)$ son **multiplicadores de impacto**. Por ejemplo, el coeficiente $\phi_{12}(0)$ es el impacto instant√°neo de un cambio en una unidad de $\varepsilon_{zt}$ en $y_t$. 
2) De la misma manera, los elementos $\phi_{12}(1)$ y $\phi_{12}(1)$ son las respuestas en el siguiente per√≠odo de los cambios unitarios de $\varepsilon_{y(t-1)}$ y $\varepsilon_{z(t-1)}$ en $y_t$, respectivamente. La actualizaci√≥n un per√≠odo hac√≠a adelante tambi√©n indica que $\phi_{12}(1)$ y $\phi_{12}(1)$ representan los efectos de los cambios unitarios de $\varepsilon_{yt}$ y $\varepsilon_{zt}$ en $y_{t+1}$.

Los efectos acumulados de los impulsos unitarios en $\varepsilon_{yt}$  y/o $\varepsilon_{zt}$  se pueden obtener mediante la suma apropiada de los coeficientes de las funciones de impulso-respuesta. Por ejemplo, tenga en cuenta que, despu√©s de $n$ periodos, el efecto de $\varepsilon_{zt}$  en el valor de $y_{t+n}$ es $\phi_{12}(n)$. Por lo tanto, despu√©s de $n$ periodos, la suma acumulada de los efectos de $\varepsilon_{zt}$  en la secuencia { $y_t$ } es $\eqalign{\sum_{i=0}^n \phi_{12}(i)}$

Cuando $n$ se aproxima al infinito se produce el efecto total acumulado. Si se supone que las secuencias { $y_t$ } y { $z_t$ } son estacionarias, debe darse el caso de que para todos los $j$ y $k$, los valores de $\phi_{12}(i)$ convergen a cero a medida que $i$ se hace grande. Esto ocurre porque los choques no pueden tener un efecto permanente en una serie estacionaria. 

Los cuatro conjuntos de coeficientes $\phi_{11}(i)$, $\phi_{12}(i)$, $\phi_{21}(i)$ y $\phi_{22}(i)$ se denominan funciones de impulso-respuesta. 
El dibujo de las funciones impulso-respuesta (es decir, el dibujo de los coeficientes de $\phi_{jk}(i)$  en funci√≥n de $i$) es una forma pr√°ctica de representar visualmente el comportamiento de las series { $y_t$ } y { $z_t$ } en respuesta a los diversos choques. 

Suponga que las estimaciones de las ecuaciones $i$ y $ii$ arrojan los valores:
* $a_{10}=a_{20}=0$, $a_{11}=a_{22}=0.7$, y $a_{12}=a_{21}=0.2$.
* los elementos de la matriz $\Sigma$ son tales que $\sigma_1^2=\sigma_2^2$
* el coeficiente de correlaci√≥n entre $e_{1t}$ y $e_{2t}$ es $\rho_{12}=0.8$.
* Por lo tanto, $e_{1t}=\varepsilon_{yt}-0.8\varepsilon_{zt}$ y $e_{2t}=\varepsilon_{zt}$   

Los paneles (a) y (b) de la figura de abajo muestran los efectos de los choques unitarios de $\varepsilon_{zt}$  y $\varepsilon_{yt}$  en las trayectorias temporales de las secuencias { $y_t$ } y { $z_t$ }. 

![image](https://github.com/alvaroperdomo/World-Econometrics/assets/127871747/804ef3dc-2e0e-4fd7-bbaa-69ced830d223)

Como se muestra en el Panel (a), un choque de una unidad en $\varepsilon_{zt}$ hace que $z_t$  salte una unidad y que $y_t$ salte $0.8$ unidades. En el siguiente per√≠odo, $\varepsilon_{z(t+1)}$ vuelve a cero, pero la naturaleza autorregresiva del sistema es tal que $y_{t+1}$ y $z_{t+1}$ no regresa inmediatamente a sus valores a largo plazo. 
Como $z_{t+1}=0.2y_t+0.7z_t+\varepsilon_{z(t+1)}$, se deduce que $z_{t+1}=0.2(0.8)+0.7(1)=0.86$. De manera similar, $y_{t+1}=0.7y_t+0.2z_t=0.76$. Como se puede ver en la figura, los valores subsiguientes de las secuencias { $y_t$ } y { $z_t$ } convergen a sus niveles de largo plazo.

Los efectos de un choque unitario de $\varepsilon_{yt}$  se muestran en el Panel (b) de la figura. Puede ver la asimetr√≠a de la descomposici√≥n inmediatamente comparando los dos gr√°ficos. Un choque unitario en $\varepsilon_{yt}$ hace que el valor de $y_t$ aumente en una unidad; sin embargo, no hay un efecto contempor√°neo sobre el valor de $z_t$, de modo que $y_t=1$ y $z_t=0$. En el per√≠odo subsiguiente, $\varepsilon_{y(t+1)}$ vuelve a cero. La naturaleza autorregresiva del sistema es tal que 
$y_{t+1}=0.7y_t+0.2z_t=0.7$ y $z_{t+1}=0.2y_t+0.7z_t=0.2$. Los puntos restantes en la figura son los impulso-respuesta para los per√≠odos $t+2$ a $t+20$. Como el sistema es estacionario, los impulso-respuesta finalmente decaen.

Un problema clave relacionado con las funciones impulso-respuesta es que se construyen utilizando los coeficientes estimados. Como cada coeficiente se estima de forma imprecisa, los impulso-respuesta tambi√©n contienen errores. El problema es construir intervalos de confianza alrededor de los impulso-respuesta que permitan la incertidumbre de par√°metros inherente al proceso de estimaci√≥n. 

Para ilustrar la metodolog√≠a, considere la siguiente estimaci√≥n de un modelo $AR(1):y_t=0.6y_{t-1}$ donde el estad√≠stico $t$ de $a_1$ es $4$, es decir el coeficiente parece bien estimado. 

Es f√°cil configurar la funci√≥n impulso-respuesta: para cualquier nivel dado de $y_{t-1}$, un choque unitario de $\varepsilon_t$  aumentar√° $y_t$ en una unidad. En per√≠odos subsiguientes, $y_{t+1}$ ser√° $0.6$ y $y_{t+1}$  ser√° $0.6^2$. Como puede verificar f√°cilmente, la funci√≥n impulso-respuesta se puede escribir como $\phi(i)=0.6^i$.
Observe que la estimaci√≥n puntual del coeficiente $AR(1)$ es de $0.6$ con una desv√≠aci√≥n est√°ndar de $0.15$ ($0.15=\frac{0.6}{4}$). Si estamos dispuestos a suponer que el coeficiente se distribuye normalmente, hay una probabilidad del 95% de que el valor real se encuentre dentro del intervalo de dos desviaciones est√°ndar $0.3‚Äì0.9$. Como tal, el patr√≥n de decaimiento podr√≠a estar en cualquier lugar entre $\phi(i)=0.9^i$ y $\phi(i)=0.3^i$. 

El problema es mucho m√°s complicado en los sistemas de orden superior, ya que los coeficientes estimados se correlacionar√°n. Adem√°s, es posible que no se desee asumir la normalidad. Una forma de obtener los intervalos de confianza deseados del proceso $AR(p)$ $y_t=a_0+a_1y_{t-1}+...+a_py_{t-p}+\varepsilon_t$ es realizar el siguiente estudio de Monte Carlo:
   1) Calcule los coeficientes $a_0$ a $a_p$ usando $MCO$ y guarde los residuos. Sea $\hat{a_i}$ el valor estimado de $a_i$ y sean { $\hat{\varepsilon_i}$ } los residuos estimados.
   2) Para un tama√±o de muestra de tama√±o $T$, seleccione n√∫meros aleatorios para representar la secuencia { $\varepsilon_i$ }. Por lo tanto, tendr√° una serie simulada de longitud T$, llamada $\varepsilon_t^s$, que deber√≠a tener las mismas propiedades que el verdadero proceso de error. Use estos n√∫meros aleatorios para construir la secuencia simulada { $y_t^s$ } como $y_t^s=\hat{a_0}+\hat{a_1}y_{t-1}^s+...+\hat{a_p}y_{t-p}^s+\varepsilon_t^s$ (Aseg√∫rese de que inicializa correctamente la serie para eliminar los efectos de las condiciones iniciales.)
   3) Ahora act√∫e como si no conociera los valores de los coeficiente utilizados para generar la serie $y_t^s$. Calcule $y_t^s$ como un proceso $AR(p)$ y obtenga la funci√≥n de impulso-respuesta. Si repite el proceso varios miles de veces, puede generar varios miles de funciones impulso-respuesta. Use estas funciones para construir los intervalos de confianza (por ejemplo, puede construir el intervalo que excluya el 2.5% m√°s bajo y el 2.5% m√°s alto de las respuestas para obtener un intervalo de confianza del 95%).

El beneficio de este m√©todo es que no necesita hacer supuestos especia-les con respecto a la distribuci√≥n de los coeficientes autorregresivos. El c√°lculo real de los intervalos de confianza es solo un poco m√°s complicado en un $VAR$. 

Considere el sistema de dos variables $i$  y $ii$. El problema se complica porque los residuos de la regresi√≥n est√°n correlacionados. Como tal, se necesita escoger aleatoriamente $e_{1t}$ y $e_{2t}$ de tal manera que se mantenga la estructura apropiada del error. Un m√©todo simple consiste en escoger aleatoriamente $e_{1t}$ y usar el valor de $e_{2t}$ que corresponde a ese mismo per√≠odo. Si usa una descomposici√≥n de Choleski tal que $b_{21}=0$, construya $\varepsilon_{yt}$ y $\varepsilon_{zt}$  utilizando $e_{1t}=\varepsilon_{yt}-b_{12}\varepsilon_{zt}$ y $e_{2t}=\varepsilon_zt$.

## La Descomposici√≥n de Varianza

Otra ayuda √∫til para descubrir las interrelaciones entre las variables en el sistema es la descomposici√≥n de varianza del error de pron√≥stico. 

Retome la ecuaci√≥n $\mathbf{x_t= A_0 + A_1x_{t-1}+e_t}$, asuma que conoce los coeficientes de $\mathbf{A_0}$ y $\mathbf{A_1}$ y quiere pronosticar los diversos valores de $\mathbf{x_{t+1}}$ condicionados al valor observado de $\mathbf{x_t}$. Actualizando esta ecuaci√≥n $n$ per√≠odos hacia adelante y tomando la expectativa condicionada en $t$ de $\mathbf{x_{t+n}}$, se obtiene $E_t \mathbf{x_{t+n}}$. Entonces,

* El error de pron√≥stico un periodo hacia adelante es $\mathbf{x_{t+1}} - E_t\mathbf{x_{t+1}}=e_{t+1}$ 
* El error de pron√≥stico dos periodos hacia adelante es $\mathbf{x_{t+2}} - E_t\mathbf{x_{t+2}}=e_{t+2} + A_1e_{t+1}$.
* El error de pron√≥stico ùëõ periodos hacia adelante es $\eqalign{\mathbf{x_{t+n}} - E_t\mathbf{x_{t+n}}=\sum_{i=0}^{n-1}A_1^ie_{t+n-i}}$

Tambi√©n podemos considerar estos errores de pron√≥stico en t√©rminos de $\eqalign{ \mathbf{x_t=\mu+\sum_{i=1}^p\phi_i \varepsilon_{t-i}}}$ (es decir, la forma $VMA$ del modelo estructural). 
Por supuesto, los modelos $VMA$ y $VAR$ contienen exactamente la misma informaci√≥n, pero es conveniente describir las propiedades de los errores de pron√≥stico en t√©rminos de la secuencia { $\mathbf{\varepsilon_{t-i}}$ }. 

Si usamos $\eqalign{ \mathbf{x_t=\mu+\sum_{i=1}^p\phi_i \varepsilon_{t-i}}}$ para pronosticar condicionalmente $\mathbf{x_{t+1}}$, un periodo hacia adelante el error de pron√≥stico es $\mathbf{\phi_0 \varepsilon_{t+i}}$. En general, $\eqalign{ \mathbf{x_t=\mu+\sum_{i=0}^\inf \phi_i \varepsilon_{t+n-i}}}$ de modo que el error de pron√≥stico del periodo $n$ es $\eqalign{\mathbf{x_{t+n}} - E_t\mathbf{x_{t+n}}=\sum_{i=0}^{n-1}\phi_i \varepsilon_{t+n-i}}$ 

Centr√°ndonos √∫nicamente en la secuencia { $y_t$ }, vemos que el error de pronostico $n$ periodos hac√≠a adelante es 

$\eqalign{y_{t+n}-E_t y_{t+n}= \sum_{i=0}^{n-1}[\phi_{11}(i) \varepsilon_{y(t+n-i)} + \phi_{12}(i) \varepsilon_{z(t+n-i)}]}$

La varianza del error de pron√≥stico $n$ periodos hacia adelante de $y_{t+n}$ es: $\eqalign{[\sigma_y(n)]^2=\sum_{i=0}^{n-1}(\sigma_y^2[\phi_{11}(i)]^2 + \sigma_z^2[\phi_{12}(i)]^2)}$. Debido a que todos los valores $[\phi_{jk}(i)]^2$ son necesariamente no negativos, la varianza del error de pron√≥stico aumenta a medida que aumenta el horizonte de pro-n√≥stico. 

Es posible descomponer la varianza del error de previsi√≥n $n$ periodos hacia adelante en las proporciones debidas a cada choque. Las proporciones de $[\sigma_y(n)]^2$ debidas a choques en las secuencias { $\varepsilon_{yt}$ } y { $\varepsilon_{zt}$ } son $\eqalign{\frac{\sum_{i=0}^{n-1}\sigma_y^2[\phi_{11}(i)]^2}{[\sigma_y(n)]^2}}$ y  $\eqalign{\frac{\sum_{i=0}^{n-1}\sigma_z^2[\phi_{11}(i)]^2}{[\sigma_y(n)]^2}}$ respectivamente. 

**La descomposici√≥n de varianza del error de pron√≥stico nos dice la proporci√≥n de los movimientos en una secuencia debido a sus "propios" choques contra los choques de la otra variable.** 
* Si los choques $\varepsilon_{zt}$ no explican la varianza del error de pron√≥stico de $y_t$ en todos los horizontes de pron√≥stico, podemos decir que la secuencia { $y_t$ } es ex√≥gena [en esta circunstancia, { $y_t$ } evoluciona independientemente de los choques de $\varepsilon_{zt}$ y de la secuencia { $z_t$ }].
* En el otro extremo, los shocks $\varepsilon_{zt}$ podr√≠an explicar toda la varianza del error de pron√≥stico en la secuencia { $y_t$ } en todos los horizontes de pron√≥stico, de modo que { $y_t$ } ser√≠a completamente end√≥geno. 

En la investigaci√≥n aplicada, es usual que una variable explique casi toda su varianza de error de pron√≥stico en horizontes cortos y proporciones m√°s peque√±as en horizontes m√°s largos. Esperamos este patr√≥n si los choques de $\varepsilon_{zt}$ tuvieran un bajo efecto contempor√°neo en $y_t$, pero afectaran la secuencia { $y_t$ } de forma rezagada.

La descomposici√≥n de varianza tiene el mismo problema inherente en el an√°lisis de la funci√≥n impulso-respuesta: Para identificar las secuencias $\varepsilon_{yt}$ y $\varepsilon_{zt}$, es necesario restringir la matriz $\mathbf{B}$. La descomposici√≥n de Choleski que utilizamos previamente requiere que toda la varianza del error de pron√≥stico de un per√≠odo de $z_t$ se deba a $\varepsilon_{zt}$. Si utilizamos el ordenamiento alternativo, toda la varianza del error de pron√≥stico de un per√≠odo de $y_t$ se deber√≠a a $\varepsilon_{yt}$. Los efectos de estos supuestos alternativos se reducen en horizontes de pron√≥stico m√°s largos. 

En la pr√°ctica, es √∫til examinar las descomposiciones de varianza en varios horizontes de pron√≥stico. A medida que $n$ aumenta, las descomposiciones de varianza deber√≠an converger. Adem√°s, si el coeficiente de correlaci√≥n $\rho_{12}$ es significativamente diferente de cero, es habitual obtener las descomposiciones de varianza en varios ordenamientos.

Sin embargo, el an√°lisis impulso-respuesta y las descomposiciones de va-rianza pueden ser herramientas √∫tiles para examinar las relaciones entre variables econ√≥micas. Si las correlaciones entre las diversas innovaciones son peque√±as, es probable que el problema de identificaci√≥n no sea especialmente importante. Los ordenamientos alernativos deber√≠an producir impulso-respuesta y descomposiciones de varianza similares. Por supuesto, los movimientos contempor√°neos de muchas variables econ√≥micas est√°n altamente correlacionados.

## Pruebas de Hip√≥tesis

En principio, no hay nada que impida incorporar una gran cantidad de variables en el $VAR$. Es posible construir un $VAR$ de $n$ ecuaciones con cada ecuaci√≥n conteniendo $p$ rezagos de todas las $n$ variables en el sistema. Por lo general, uno quiere incluir aquellas variables que tienen importantes efectos econ√≥micos entre s√≠. No obstante, tenga en cuenta que los grados de libertad disminuyen r√°pidamente a medida que se incluyen m√°s variables. [^6] 

[^6]: Por ejemplo, al usar datos con 5 rezagos, la inclusi√≥n de una variable adicional usa 5 grados adicionales de libertad en cada ecuaci√≥n. 

Un examen cuidadoso del modelo te√≥rico relevante lo ayudar√° a seleccionar el conjunto de variables para incluir en su modelo $VAR$. Un $VAR$ de $n$ ecuaciones puede ser representado por:

$$ {\left\lbrack \matrix{ x_{1t} \cr x_{2t} \cr \dots \cr x_{nt} } \right\rbrack} = \left\lbrack \matrix{ A_{10} \cr A_{20} \cr \dots \cr A_{n0} } \right\rbrack + \left\lbrack \matrix{A_{11}(L) & A_{12}(L) & \dots & A_{1n}(L) \cr A_{21}(L) & A_{22}(L) & \dots & A_{2n}(L) \cr \dots & \dots & \dots & \dots \cr A_{n1}(L) & A_{n2}(L) & \dots & A_{nn}(L) } \right\rbrack  \left\lbrack \matrix{ x_{1(t-1)} \cr x_{2(t-1)} \cr \dots \cr x_{n(t-1)} } \right\rbrack + \left\lbrack \matrix{ e_{1t} \cr e_{2t} \cr \dots \cr e_{nt} } \right\rbrack
$$

* los $A_{i0}$ son los interceptos,
* los $A_{ij}(L)$ son los polinomios en el operador de rezagos $L$. Los coeficientes individuales de los $A_{ij}(L)$ se denotan por $a_{ij}(1), a_{ij}(2)$. Como todas las ecuaciones tienen la misma longitud de rezagos, los polinomios $A_{ij}(L)$ son todos del mismo grado.
* Los t√©rminos $e_{1t}$ son perturbaciones ruido blanco que pueden estar correlacionadas entre s√≠.
* La matriz de varianzas y covarianza $\mathbf{\Sigma}$ tiene dimensi√≥n ($n \times n$)

Adem√°s de la determinaci√≥n del conjunto de variables a incluir en el $VAR$, es importante determinar la longitud apropiada de rezagos. Un posible procedimiento es permitir diferentes longitudes de rezago para cada variable en cada ecuaci√≥n. Sin embargo, para preservar la simetr√≠a del sistema (y poder usar $MCO$ de manera eficiente), es com√∫n usar la misma longitud de rezagos para todas las ecuaciones. [^7] 

[^7]: Siempre que haya regresores id√©nticos en cada ecuaci√≥n, las estimaciones MCO son consistentes y asint√≥ticamente eficientes. 



















