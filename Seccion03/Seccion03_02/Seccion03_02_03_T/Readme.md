## SECCI√ìN 3.2.3:
# La Metodolog√≠a de Johansen

Los estimadores de m√°xima verosimilitud de Johansen (1988): 
* evitan el uso de estimadores de dos pasos[^1],
* pueden estimar y probar la presencia de m√∫ltiples vectores de cointegraci√≥n, y
* permiten probar versiones restringidas de los vectores de cointegraci√≥n y la velocidad de los par√°metros de ajuste.[^2] 

[^1]: **Tal como ocurre en la metodolog√≠a de Engle y Granger (1987) visto previamente.
[^2]: **A menudo, es interesante determinar si es posible verificar una teor√≠a probando restricciones en las magnitudes de los coeficientes estimados**

El procedimiento de Johansen (1988) se basa en gran medida en la relaci√≥n entre el rango de una matriz y sus ra√≠ces caracter√≠sticas. Este no es m√°s que una generalizaci√≥n multivariada de la prueba $DF$ utilizada para analizar la presencia de ra√≠z unitaria en los modelos univariados. 

En el caso univariado, es posible ver que la estacionariedad de { $y_t$ } depende de $a_1$; es decir, dados $y_t=a_1y_{t-1}+\varepsilon_t$ o $\Delta y_t=(a_1-1)y_{t-1}+\varepsilon_t$:
* Si $(a_1-1)=0$, el proceso { $y_t$ } tiene una ra√≠z unitaria.
* Descartando el caso en el que { $y_t$ } es explosivo, si $(a_1-1)‚â†0$ podemos concluir que la secuencia { $y_t$ } es estacionaria.

Las tablas de Dickey-Fuller proporcionan los estad√≠sticos apropiados para probar formalmente la hip√≥tesis nula $(a_1-1)=0$.

Consideremos la generalizaci√≥n al caso multivariado con $n$ variables; asuma que el vector $\mathbf{x_t}$ de $n$ variables, se comporta como $\mathbf{x_t=A_1x_{t-1}+\varepsilon_t}$  as√≠ que $\mathbf{\Delta x_t=A_1x_{t-1}-x_{t-1}+\varepsilon_t=(A_1-I)x_{t-1}+\varepsilon_t=\pi x_{t-1}+\varepsilon_t}$ donde 
* $\mathbf{\varepsilon_t}$ es un vector ( $n\times 1$ ),
* $\mathbf{A_1}$ es una matriz ( $n\times n$ ) de par√°metros, 
* $\mathbf{I}$ es una matriz identidad ( $n\times n$ ),
* $\mathbf{\pi}$ se define como $\mathbf{(A_1-I)}$.

El rango de $\mathbf{(A_1-I}$ es igual al n√∫mero de vectores de cointegraci√≥n. Por analog√≠a con el caso univariado, si $\mathbf{(A_1-I}$  tiene solo ceros, de modo que el $rango(\pi)=0$, todas las secuencias { $x_{it}$ } tienen ra√≠z unitaria. En esta situaci√≥n, dado que no hay una combinaci√≥n lineal de los procesos { $x_{it}$ } que sea estacionaria, las variables no se cointegran. Descartando la presencia de ra√≠ces caracter√≠sticas mayores que $1$ y si el $rango(\pi)=n$, $\mathbf{\Delta x_t=\pi x_{t-1} + \varepsilon_t}$ es un sistema convergente de ecuaciones en diferencias, de modo que todas las variables son estacionarias.

Hay varias formas de generalizar $\mathbf{\Delta x_t=\pi x_{t-1}+\varepsilon_t}$. Por ejemplo, la ecuaci√≥n se modifica f√°cilmente si se considera la presencia de un intercepto; simplemente asuma $\mathbf{\Delta x_t=A_0 \pi x_{t-1}+\varepsilon_t}$ donde $$ \mathbf{A_0}={\left\lbrack \matrix{ a_{10} \cr a_{20} \cr \dots \cr a_{n0} } \right\rbrack}. El efecto de incluir los diversos $a_{i0}$ es permitir la posibilidad de una tendencia lineal en el proceso de generaci√≥n de datos. Lo ideal es incluir el intercepto si las variables exhiben una tendencia decidida a aumentar o a disminuir. Aqu√≠, el rango de $\pi$ se puede ver como el n√∫mero de relaciones de cointegraci√≥n existentes en los datos sin tendencia. En el largo plazo, $\mathbf{\pi x_{t-1}=0}$ tal que el valor esperado de cada secuencia { $\Delta x_{it}$ } es $a_{i0}$. Al agregar todos estos cambios en el tiempo se obtiene la expresi√≥n determinista $a_{i0}t$.

Las figuras de abajo ilustran los efectos de incluir un intercepto en el proceso de generaci√≥n de datos. 

![image](https://github.com/alvaroperdomo/World-Econometrics/assets/127871747/61152b61-d2a2-4dab-8f67-133f11dde731)

En las figuras, se generaron dos secuencias aleatorias, { $\varepsilon_{yt}$ } y { $\varepsilon_{zt}$ }, con $100$ observaciones cada una. Por otro lado, se asumi√≥ $y_0=z_0=0$, y que los siguientes $100$ valores de las secuencias { $y_t$ } y { $z_t$ } eran

de modo que la relaci√≥n de cointegraci√≥n es $y_t=z_t$

* En la figura de la izquierda, puede ver que cada secuencia se asemeja a un proceso aleatorio y que ninguno se aleja demasiado del otro.
* En la figura del centro se agregan interceptor de manera que $a_{10}=a_{20}=0.1$; ahora cada serie tiende a aumentar $0.1$ unidades en cada per√≠odo. Adem√°s del hecho de que cada secuencia comparte la misma tendencia estoc√°stica, tenga en cuenta que cada una tambi√©n tiene la misma tendencia de tiempo determinista. El hecho de que cada uno tenga la misma tendencia determinista no es el resultado de la equivalencia entre $a_{10}$ y $a_{20}$; ya que $y_t$ y $z_t$ est√°n cointegrados, la soluci√≥n general a $\mathbf{\Delta x_t=A_0+ \pi x_{t-1}+\varepsilon_t}$ requiere que cada uno tenga la misma tendencia lineal.
* Para verificar esto, la figura de la derecha establece $a_{10}=0.1$ y $a_{20}=0.4$. De nuevo, las secuencias tienen las mismas tendencias estoc√°sticas y deterministas.

A continuaci√≥n veremos que manipulando apropiadamente los elementos de $A_0$ es posible incluir una constante en los vectores de cointegraci√≥n sin necesidad de in-cluir una tendencia de tiempo determinista al sistema.

Una forma de incluir una constante en las relaciones de cointegraci√≥n es restringir los valores de los diversos $a_i0$. Por ejemplo, si $rango(\pi)=1$, las filas de $\pi$ pueden diferir s√≥lo en un escalar, por lo que es posible escribir cada secuencia { $\Delta x_{it}$ } en $\mathbf{\Delta x_t=A_0+ \pi x_{t-1}+\varepsilon_t}$ como:

$\Delta x_{1t}= (\pi_{11}x_{1(t-1)} + \pi_{12}x_{2(t-1)} + \dots + \pi_{1n}x_{1(t-1)}) + a_{10} + \varepsilon_{1t}$

$\Delta x_{2t}=s_2(\pi_{21}x_{2(t-1)} + \pi_{22}x_{2(t-1)} + \dots + \pi_{2n}x_{2(t-1)}) + a_{20} + \varepsilon_{2t}$

$\dots$

$\Delta x_{nt}=s_n(\pi_{n1}x_{n(t-1)} + \pi_{n2}x_{n(t-1)} + \dots + \pi_{nn}x_{n(t-1)}) + a_{n0} + \varepsilon_{nt}$

donde $s_i$ es un escalar tal que $s_i \pi_{1j}= \pi_{ij}$  

Si $a_{i0}$ se puede restringir tal que $a_i0=s_ia_{10}$, todas las secuencias { $\Delta x_{it}$ } se pueden escribir con la constante incluida en el vector de cointegraci√≥n:

$\Delta x_{1t}= (\pi_{11}x_{1(t-1)} + \pi_{12}x_{2(t-1)} + \dots + \pi_{1n}x_{1(t-1)} + a_{10}) + \varepsilon_{1t}$

$\Delta x_{2t}=s_2(\pi_{21}x_{2(t-1)} + \pi_{22}x_{2(t-1)} + \dots + \pi_{2n}x_{2(t-1)} + a_{20}) + \varepsilon_{2t}$

$\dots$

$\Delta x_{nt}=s_n(\pi_{n1}x_{n(t-1)} + \pi_{n2}x_{n(t-1)} + \dots + \pi_{nn}x_{n(t-1)} + a_{20}) + \varepsilon_{nt}$

o en la forma compacta $\mathbf{\Delta x_t= A_0 + \pi^* x_{t-1}^* + \varepsilon_t}$ donde 

$\eqalign{\mathbf{x_t} = {\left\lbrack \matrix{x_{1t} \cr x_{2t} \cr \dots \cr x_{nt} } \right\rbrack}}$, 
$\eqalign{\mathbf{x_{t-1}^*} = {\left\lbrack \matrix{x_{1(t-1)} \cr x_{2(t-1)} \cr \dots \cr x_{n(t-1)} } \right\rbrack}}$,     y 

$\eqalign{\mathbf{ \pi* } = {\left\lbrack \matrix{\pi_{11} & \pi_{12} & \dots & \pi_{1n} \cr \pi_{21} & \pi_{22} & \dots & \pi_{2n} \cr \dots & \dots & \dots & \dots \cr \pi_{n1} & \pi_{n2} & \dots & \pi_{nn} } \right\rbrack}}$ 

La caracter√≠stica interesante de $\mathbf{\Delta x_t=A_0 + \pi^* x_{t-1}^* + \varepsilon_t}$ es que la tendencia lineal se elimina del sistema. En esencia, los diversos $a_io$ se han modificado de tal manera que la soluci√≥n general para cada { $x_it$ } no contiene una tendencia temporal. La soluci√≥n al conjunto de ecuaciones en diferencias representadas $\mathbf{\Delta x_t=A_0 + \pi^* x_{t-1}^* + \varepsilon_t}$ por es tal que se espera que todos los $Delta x_{it}$ sean iguales a cero cuando $\pi_{11} x_{1(t-1)} + \pi_{12} x_{2(t-1)} + \dots + \pi_{1n} x_{n(t-1)} + a_{i0} =0$.

Para resaltar la diferencia entre $\mathbf{\Delta x_t=A_0+ \pi x_{t-1}+\varepsilon_t}$ y $\mathbf{\Delta x_t=A_0 + \pi^* x_{t-1}^* + varepsilon_t}$, la figura de abajo ilustra las consecuencias de utilizar $a_10=0.1$ y $a_20=-0.1$.  

![image](https://github.com/alvaroperdomo/World-Econometrics/assets/127871747/217d2e36-944c-493c-8cab-b45d1ff27ff6)

Se puede ver que ninguna secuencia contiene una tendencia determinista. De hecho, para los datos que se muestran en la figura, la tendencia desaparecer√° siempre que seleccionemos valores de los interceptos manteniendo la relaci√≥n $a_10=-a_20$.

**Algunos econometristas prefieren incluir un intercepto en el vector de cointegraci√≥n junto con un intercepto fuera de √©ste.** Esto tiene sentido si las variables contienen un intercepto y si la teor√≠a econ√≥mica sugiere que el vector de cointegraci√≥n contiene un intercepto. Sin embargo, debe quedar claro que el intercepto en el vector de cointegraci√≥n no se identifica en presencia de un intercepto fuera de este. Despu√©s de todo, alguna parte del intercepto no restringido siempre puede incluirse en el vector de cointegraci√≥n. 

En t√©rminos del ejemplo anterior, el sistema siempre puede escribirse como:

$\Delta x_{1t}= (\pi_{11}x_{1(t-1)} + \pi_{12}x_{2(t-1)} + \dots + \pi_{1n}x_{1(t-1)} + b_{10}) + b_{11} + \varepsilon_{1t}$

$\Delta x_{2t}=s_2(\pi_{21}x_{2(t-1)} + \pi_{22}x_{2(t-1)} + \dots + \pi_{2n}x_{2(t-1)} + b_{20}) + b_{21} + \varepsilon_{2t}$

$\dots$

$\Delta x_{nt}=s_n(\pi_{n1}x_{n(t-1)} + \pi_{n2}x_{n(t-1)} + \dots + \pi_{nn}x_{n(t-1)} + b_{n0}) + b_{n1} + \varepsilon_{nt}$

donde  $s_i b_{10} + b_{11}= a_{10}$  

Todo lo que se hace es dividir $a_{10}$ en dos partes y colocar una parte dentro de la relaci√≥n de cointegraci√≥n. Es necesaria alguna estrategia de identificaci√≥n ya que la proporci√≥n del intercepto a incluir en el vector de cointegraci√≥n es arbitraria. 

De los gr√°ficos previos, note que es necesario una constante fuera de la relaci√≥n de cointegraci√≥n para capturar los efectos de una tendencia sostenida de las variables a aumentar (o a disminuir). La mayor√≠a de los investigadores incluyen interceptos si los datos se asemejan a los gr√°ficos donde ambos interceptos eran 0.1 o donde los interceptos eram 0.1 y 0.4. De lo contrario, incluyen interceptos en el vector de cointegraci√≥n o excluyen por completo a los regresores deterministas. Si no est√° seguro, puede usar los m√©todos que se describen m√°s adelante para probar si las desviaciones se pueden restringir adecuadamente. R permite incluir una tendencia de tiempo determinista en el modelo. Claro que es mejor evitar el uso de la tendencia como variable explicativa a menos que tenga una buena raz√≥n para incluirla en el modelo. Johansen (1994) discute el papel de los regresores deterministas en una relaci√≥n de cointegraci√≥n.

Al igual que con la prueba $ADF$, el modelo multivariado tambi√©n puede generalizarse para permitir un proceso autorregresivo de orden superior. 

Considere $x_t = A_1x_{t-1} + A_2x_{t-2}  + \dots +  A_px_{t-p} + \varepsilon_t$ donde $\eqalign{\mathbf{x_t} = {\left\lbrack \matrix{x_{1t} \cr x_{2t} \cr \dots \cr x_{nt} } \right\rbrack}}$ y $\mathbf{\varepsilon_t}$ es un vector n-dimensional distribuido de forma independiente e id√©ntica con media cero y matriz de varianza $\Sigma_\varepsilon$.

Como se hizo con la prueba $ADF$ en el modelo univariado, con las sumas apropiadas, la ecuaci√≥n $\mathbf{x_t= \displaystyle\sum_{i=1}^{p} A_i x_{t-i} + \varepsilon_t}$ se puede transformar en: $\mathbf{\Delta x_t= \pi x_{t-1} +  \displaystyle\sum_{i=1}^{p-1} \pi_i \Delta x_{t-i} + \varepsilon_t}$ donde $\mathbf{\pi = -(I-\displaystyle\sum_{i=1}^p A_i)}$ y $\mathbf{\pi_i = -(I-\displaystyle\sum_{j=i+1}^p A_j)}$ 

La caracter√≠stica clave a tener en esta nueva ecuaci√≥n es el rango de la matriz $\mathbf{\pi}$ ; **el rango de $\mathbf{\pi}$ es igual al n√∫mero de vectores cointegrantes independientes**:

* si $\mathbf{rango(\pi)=0}$, la matriz es nula y $\mathbf{\Delta x_t= \pi x_{t-1} +  \displaystyle\sum_{i=1}^{p-1} \pi_i \Delta x_{t-i} + \varepsilon_t}$ es el modelo $VAR$ en las primeras diferencias.
* si $\mathbf{rango(\pi)=n}$, el proceso vectorial es estacionario.
* si $\mathbf{rango(\pi)=1}$, hay un solo vector de cointegraci√≥n y la expresi√≥n $\mathbf{\pi x_{t-1}}$ es el t√©rmino de correcci√≥n de errores.
* si $\mathbf{1 \lt rango(\pi) \lt n}$, hay m√∫ltiples vectores de cointegraci√≥n.

El n√∫mero de distintos vectores de cointegraci√≥n se puede obtener al verificar la significancia de las ra√≠ces caracter√≠sticas de $\mathbf{\pi}$. 
Sabemos que el rango de una matriz es igual al n√∫mero de sus ra√≠ces caracter√≠sticas que difieren de cero. Suponga que se obtiene la matriz $\mathbf{\pi}$ y se ordenan las $n$ ra√≠ces caracter√≠sticas de forma que $\lambda_1>\lambda_2>\dots>\lambda_n$. 

Si las variables en $\mathbf{x_t}$ no est√°n cointegradas, $\mathbf{rango(\pi)=0}$ y todas las ra√≠ces caracter√≠sticas ser√°n iguales a cero. Como $\ln{(1)}=0$, entonces cada una de las expresiones $\ln{(1 - \lambda_i)}$ ser√° igual a cero si las variables no est√°n cointegradas. 

De manera similar, si $\mathbf{rango(\pi)=1}$, $0 < ùúÜ_1 < 1$, entonces $\ln{(1 - \lambda_1)} < 0$ y $\ln{(1 - \lambda_2)} = \ln{(1 - \lambda_3)} = \dots = \ln{(1 - \lambda_n)} = 0$.

En la pr√°ctica, solo podemos obtener estimaciones de $\mathbf{\pi}$ y de sus ra√≠ces caracter√≠sticas. La prueba para el n√∫mero de ra√≠ces caracter√≠sticas que son significativamente diferentes de $1$ se puede realizar utilizando los siguientes dos estad√≠sticos de prueba:

* $\lambda_{traza}(r)=-T\displaystyle\sum_{r+1}^n \ln{(1-\hat{\lambda_i})}$ 
* $\lambda_{max}(r,r+1)=-T\ln{(1-\hat{\lambda_{r+1}})}$

donde
* $\hat{\lambda_i}$ son los valores estimados de las ra√≠ces caracter√≠sticas (tambi√©n llamados valores propios) obtenido de la matriz $\mathbf{\pi}$ estimada 
* $T$ es el n√∫mero de observaciones utilizables

El estad√≠stico $\lambda_{traza}$ prueba la hip√≥tesis nula de que el n√∫mero de diferentes vectores de cointegraci√≥n es menor o igual que $r$ frente a una alterna-tiva general. Note que $\lambda_{traza}=0$ cuando todos los $\lambda_i=0$. Cuanto m√°s lejos est√°n las ra√≠ces caracter√≠sticas estimadas de cero, m√°s negativo es $(1-\hat{\lambda_i})$  y m√°s grande es el estad√≠stico $\lambda_{traza}$. 

El estad√≠stico $\lambda_{max}$ prueba la hip√≥tesis nula de que el n√∫mero de vectores de cointegraci√≥n es $r$ frente a la alternativa de $r+1$ vectores de cointe-graci√≥n. Si el valor estimado de la ra√≠z caracter√≠stica est√° cerca de cero, $\lambda_{max}$ ser√° peque√±o.

Los valores cr√≠ticos de los estad√≠sticos $\lambda_{traza}$  y $\lambda_{max}$ se obtienen utilizan-do el enfoque de Monte Carlo. La distribuci√≥n de estos estad√≠sticos depende de dos cosas:
1) El n√∫mero de componentes no estacionarios bajo la hip√≥tesis nula (es decir, $n-r$).
2) La forma del vector $A_0$. Es decir: 
    * si no incluye interceptos ni en la ecuaci√≥n ni en el vector de cointegraci√≥n.
    * si incluye un intercepto en la ecuaci√≥n.
    * si incluye un intercepto en el vector de cointegraci√≥n.

Es importante anotar que estos estad√≠sticos necesitan que sus residuos sean ruido blanco. Cualquier evidencia de que los errores no son ruido blanco generalmente significa que las longitudes de rezago son demasiado cortas. 

En la prueba de Johansen, es importante determinar correctamente la forma de los regresores deterministas. Por ejemplo, los valores cr√≠ticos de los estad√≠sticos $\lambda_{traza}$ y $\lambda_{max}$ son m√°s peque√±os sin ning√∫n tipo de regresores deterministas y m√°s grandes con un intercepto en el vector de cointegraci√≥n. 
En lugar de plantear con cautela la forma de $A_0$, es posible probar formas restringidas del vector [^*]. La idea clave de todas las pruebas de hip√≥tesis es que **si hay $r$ vectores de cointegraci√≥n, solo estas $r$ combinaciones lineales de las variables son estacionarias**. Todas las dem√°s combinaciones lineales son no estacionarias. Por lo tanto, suponga que se reestima el modelo restringiendo los par√°metros de $\pi$. Si las restricciones no son vinculantes, debe encontrar que el n√∫mero de vectores de cointegraci√≥n no ha disminuido. 

[^*]: Uno de los aspectos m√°s interesantes del procedimiento de Johansen es que permite probar formas restringidas de los vectores de cointegraci√≥n.

Para probar la presencia de un intercepto en el vector de cointegraci√≥n en oposici√≥n al intercepto no restringido $A_0$, estime las dos formas del modelo. Denote 

* las ra√≠ces caracter√≠sticas ordenadas de la matriz no restringida $\pi$ por $\hat{\lambda_i},\dots,\hat{\lambda_n}$, y
* las ra√≠ces caracter√≠sticas del modelo con los interceptos en los vectores de cointegraci√≥n por $\hat{\lambda_i^* },\dots,\hat{\lambda_n^* }$. 

Suponga que la forma no restringida del modelo tiene $r$ ra√≠ces caracter√≠sticas distintas de cero.  Asint√≥ticamente, el estad√≠stico 
$-T\displaystyle\sum_{i=r+1}^n[\ln{(1-\hat{\lambda_i^* )}}-\ln{(1-\hat{\lambda_n})}]$ tiene una distribuci√≥n $\chi^2$ con $(n-r)$ grados de libertad. La intuici√≥n detr√°s de la prueba es que todos los valores de $\ln{1-\hat{\lambda_i^*}}$ y \ln{1-\hat{\lambda_n}} deben ser equivalentes si la restricci√≥n no es vinculante. Por lo tanto, valores peque√±os del estad√≠stico de prueba implican que est√° permitido incluir el intercepto en el vector de cointegraci√≥n. Sin embargo, la probabilidad de encontrar una combinaci√≥n lineal estacionaria de las ùëõ variables es mayor con el intercepto en el vector de cointegraci√≥n que si el intercepto est√° ausente de este. 

Por lo tanto, un valor grande de $\hat{\lambda_{r+1}^* }$ [y en consecuencia de $-T \ln{(1-\hat{\lambda_i^* )}}$], implica que la restricci√≥n infla artificialmente el n√∫mero de vectores de cointegraci√≥n. En-tonces, como lo demuestra Johansen (1991), si el estad√≠stico de prueba es suficientemente grande, es posible rechazar la hip√≥tesis nula de un intercepto en el vector de cointegraci√≥n y concluir que hay una tendencia lineal en las variables. 

La manera m√°s sencilla de comprender las pruebas de longitud de rezagos es considerar el sistema en la forma $\mathbf{\Delta x_t=\pi^* x_{t-1} + \displaystyle\sum_{i=1}^{p-1} + \varepsilon_t}$. Independientemente del rango de $\pi$, todos los $\Delta x_{t-i}$ son variables estacionarias. Entonces, a partir de Sims, Stock y Watson (1990), sabemos que los coeficientes de inter√©s en las variables estacionarias de media cero se pueden probar utilizando una distribuci√≥n normal. Dado que la longitud del rezago depende √∫nicamente de los valores de los diversos $\pi_i$, una distribuci√≥n $\chi^2$ es apropiada para probar cualquier restricci√≥n relacionada con la longitud del rezago. Como en el caso de cualquier $Var$, sea $Sigma_u$ y $Sigma_r$ las matrices de varianzas y covarianzas de los sistemas no restringidos y restringidos, respectivamente. Suponga que $c$ denota el n√∫mero m√°ximo de regresores contenidos en la ecuaci√≥n m√°s larga. El estad√≠stico de prueba $(T-c)(\ln{|\mathbf{\Sigma_r}|}-\ln{|\mathbf{\Sigma_u}|})$ se puede comparar con una distribuci√≥n $\chi^2$ con grados de libertad igual al n√∫mero de restricciones en el sistema. 

Alternativamente, puede usar el Coeficiente de Informaci√≥n de Akaike o el Coeficiente Bayesiano de Schwartz multivariado para determinar la longitud del rezago. Si desea probar la longitud del rezago para una sola ecuaci√≥n, una prueba $F$ es apropiada. Sims, Stock y Watson (1990) tambi√©n establecen que no se pueden realizar pruebas de causalidad de Granger en un sistema cointegrado usando una prueba $F$ est√°ndar. Cuando el $rango(\pi)=0$ entonces $\mathbf{\Delta x_t= \displaystyle\sum_{i=1}^{p-1} + \varepsilon_t}$. En este caso (es decir, en un $VAR$ en diferencias), s√≥lo hay variables estacionarias. Por lo tanto, las pruebas de causalidad de Granger se pueden realizar utilizando una distribuci√≥n $F$ est√°ndar. Sin embargo, si las variables est√°n cointegradas, $\mathbf{\Delta x_t=\pi^* x_{t-1} + \displaystyle\sum_{i=1}^{p-1} + \varepsilon_t}$, una prueba de causalidad de Granger involucra los coeficientes de $\pi$. Dado que estos coeficientes multiplican las variables no estacionarias, no es apropiado usar un estad√≠stico $F$ para probar la causalidad de Granger. Despu√©s de todo, si el $rango(\pi)=0$, es imposible escribir las restricciones de la prueba como restricciones en un conjunto de variables $I(0)$. 

Sims, Stock y Watson (1990), tambi√©n descartan las pruebas de exogenei-dad en bloque. 

## Resumen de la metodolog√≠a propuesta por Johansen

Utilice los siguientes cuatro pasos cuando implemente el procedimiento Johansen:

1) **Realice una prueba de todas las variables para evaluar su orden de integraci√≥n.**

   Grafique los datos para ver si es probable que una tendencia de tiempo lineal est√© presente en el proceso de generaci√≥n de datos. Los resultados de la prueba pueden ser bastante sensibles a la longitud del rezago, por lo que es importante tener cuidado. El procedimiento m√°s com√∫n es estimar $VAR$ de los datos no diferenciados. Luego use las mismas pruebas de longitud de rezagos que en un $VAR$ tradicional. Comience con el rezago mas largo que considere razonable y verifique si se puede acortar. Por ejemplo, si queremos probar si los rezagos $1$ a $4$ son importantes, podemos estimar los siguientes dos ùëâùê¥ùëÖ:
   * $\mathbf{x_t=A_0+A_1 x_{t-1}+A_2 x_{t-2}+A_3 x_{t-3}+A_4 x_{t-4}+e_{1t}}$
   * $\mathbf{x_t=A_0+A_1 x_{t-1}+e_{2t}}$

donde 
   * $\mathbf{x_t}$ es un vector de variables ( $n\times 1$ ),
   * $\mathbf{A_0}$ es la matriz ( $n\times 1$ ) de interceptos,
   * $\mathbf{A_1}$ son matrices ( $n\times n$  de coeficientes, y
   * $\mathbf{e_{1t}}$ y $\mathbf{e_{2t}}$ son vectores ( $n\times 1$ ) de t√©rminos de error.
   
   Calcule el primer sistema con cuatro rezagos de cada variable en cada ecuaci√≥n y llame a la matriz de varianzas y covarianzas de los residuos $\mathbf{\Sigma_4}$. Ahora estime la segunda ecuaci√≥n usando solo un rezago de cada variable en cada ecuaci√≥n y llame a la matriz de varianzas y covarianzas de los residuos $\mathbf{\Sigma_1}$. 

Aunque trabajamos con variables no estacionarias, podemos realizar pruebas de longitud de rezagos utilizando el estad√≠stico de prueba de raz√≥n de verosi-militud recomendado por Sims (1980): $(T-c)(\ln{|\mathbf{\Sigma_1}|}-\ln{|\mathbf{\Sigma_4}|})$ donde 
* $T$ es el n√∫mero de observaciones,
* $c" es el n√∫mero de par√°metros en el sistema no restringido y
* $ln{|\mathbf{\Sigma_i}|}$ es el logaritmo natural del determinante de $\mathbf{\Sigma_i}$.

Siguiendo a Sims, use la distribuci√≥n $\chi^2$ con grados de libertad igual al n√∫mero de restricciones de los coeficientes. Como cada $\mathbf{A_i}$ tiene $n^2$ coeficientes, la restricci√≥n $\mathbf{A_2=A_3=A_4=0}$  implica restricciones $3n^2$. 

Alternativamente, puede seleccionar la longitud del rezago $p$ utilizando las generalizaciones multivariadas del Criterio de Informaci√≥n de Akaike o del Criterio Bayesiano de Schwartz. En el modelo en cuesti√≥n, puede darse por ejemplo que el m√©todo general a espec√≠fico y el Criterio de Informaci√≥n de Akaike seleccionan una longitud de rezago de $2$, mientras que el Criterio Bayesiano de Schwartz selecciona una longitud de rezago de $1$. 

2) **Estime el modelo y determine el rango de $\pi$.**

   Muchos paquetes de software econom√©trico contienen una rutina para estimar el modelo. Aqu√≠, basta con decir que M√≠nimos Cuadrados Ordinarios no es apropiado porque es necesario imponer restricciones de ecuaciones cruzadas en la matriz. En la mayor√≠a de los casos, puede elegir estimar el modelo en tres formas:
   
   i) con todos los elementos de $\mathbf{A_0}$ establecidos en cero,
   
   ii) con una constante en la ecuaci√≥n, o
   
   iii) con un t√©rmino constante en el vector de cointegraci√≥n. 

3) **Analice el(los) vector(es) de cointegraci√≥n normalizados y la velocidad de los coeficientes de ajuste.**

   Por ejemplo, asuma que si seleccionamos $r=1$, el vector estimado de cointegraci√≥n $(\beta_0,\beta_1,\beta_2,\beta_3)$ es $\mathbf{\beta_t}=(0.00553, 0.41532, 0.42988, ‚àí0.42207)$. Normalizando con respecto a $\beta_1$, el vector de cointegraci√≥n normalizado es $\mathbf{\beta_t}=(‚àí0.01331, ‚àí1.0000, ‚àí1.0350, 1.0162)$.

   Asuma que los valores te√≥ricos del vector de cointegraci√≥n son $(0,‚àí1,‚àí1, 1)$. En consecuencia, considere hacer las siguientes pruebas:
   a) La prueba de $\beta_0=0$ implica una restricci√≥n en un vector de cointegraci√≥n; por lo tanto, la prueba de raz√≥n de verosimilitud tiene una distribuci√≥n $\chi^2$ con un grado de libertad.
   b) Para restringir el vector de cointegraci√≥n normalizado tal que $\beta_2=-1$ y $\beta_3=-1$ implica dos restricciones en un vector de cointegraci√≥n; por lo tanto, la prueba de raz√≥n de verosimilitud tiene una distribuci√≥n $\chi^2$ con dos grados de libertad.
   c) Para probar la restricci√≥n conjunta $\mathbf{\beta_t}=(0,‚àí1,‚àí1, 1)$ implica las tres restricciones $\beta_0=0$, $\beta_2=-1$ y $\beta_3=-1$.

4) Finalmente, **las pruebas de impulso-respuesta, descomposici√≥n de varianza y causalidad en el modelo de correcci√≥n de errores** podr√≠an ayudar a identificar un modelo estructural y determinar si el modelo estimado parece ser razonable.

<div align="center"><a href="https://enlace-academico.escuelaing.edu.co/psc/FORMULARIO/EMPLOYEE/SA/c/EC_LOCALIZACION_RE.LC_FRM_ADMEDCO_FL.GBL" target="_blank"><img src="https://github.com/alvaroperdomo/World-Econometrics/blob/main/.icons/IconCEHBotonCertificado.png" alt="World-Econometrics" width="260" border="0" /></a></div>
